Alonzo Church y Alan Turing hipotetizaron en 1936 de manera independiente que el cálculo $ λ $ y las máquinas de Turing formalizaban el concepto de cómputo \cite{Church:Unsolvable,Turing:Computable}. Esto puede parecer extraño ya que claramente los programas de computadora pueden realizar cómputos complejos que involucran números, texto, árboles, gráficas o conjuntos mientras que en el cálculo $ λ $ se está limitado a átomos, abstracciones y aplicaciones.

En este capítulo se presenta un tratamiento computacional del cálculo $ λ $ con el objetivo de explorar el tipo de conceptos matemáticos y algorítmicos que se pueden representar en él.

En la primera sección se plantean codificaciones para valores de verdad y operaciones booleanas, con esto se construye en el cálculo una operación similar a la sentencia condicional de los lenguajes de programación; en la segunda sección se exploran los números naturales y las operaciones aritméticas elementales, con esto se plantea un mecanismo de iteración; en la tercera sección se deriva un mecanismo de recursividad que permitirá representar algoritmos recursivos de manera sencilla; en la cuarta sección se presentan codificaciones de las listas, árboles y gráficas, finalmente se presenta la codificación de términos $ λ $.

Este capítulo está fuertemente influenciado por la serie de reportes técnicos llamados en la comunidad de lenguajes de programación como ``The Lambda Papers'' por Sussman y Steele \cite{Scheme:first,Steele:Imperative,Steele:Declarative,Steele:LambdaGOTO,Steele:Opcode}.

\section{Álgebra Booleana}
\label{sec:algebra-booleana}

El álgebra booleana es una rama del álgebra en donde las expresiones tienen asociado un valor de \emph{falso} o \emph{verdadero}. Estas expresiones son fundamentales en el estudio de circuitos y programas escritos en lenguajes de programación.

Los términos $ λ $ no tienen asignados un valor de verdad y las operaciones que se plantearon en los primeros dos capítulos involucraron el concepto de falso y verdadero únicamente en el metalenguaje y asociando estos valores no a los términos $ λ $ en sí, si no a propiedades de estos, por ejemplo, es falso que $ \| λx.x \| = 5 $ y es verdadero que $ (\bs{K}\, x) \reduce{β} (λx.y) $. Sin embargo es posible codificar los valores de verdad como elementos de $ Λ $ y construir abstracciones que emulen las propiedades de las operaciones booleanas bajo la $ β $-reducción. De esta manera se pueden escribir términos que, de acuerdo con la codificación establecida, representen expresiones booleanas y términos $ λ $ al mismo tiempo.

En los lenguajes de programación usualmente se mezclan las expresiones booleanas con otras expresiones y objetos a partir de \emph{predicados}, éstos son funciones con algún dominio $ X $ y codominio $ \{ \mathrm{falso},\ \mathrm{verdadero} \} $. Por ejemplo, al escribir un programa en donde se necesite tomar una desición a partir de si un número $ n $ es positivo o negativo se escribiría (en pseudocódigo):

\begin{algorithmic}
  \IF{esPositivo($ n $)}
  \STATE $ ... $
  \ELSE
  \STATE $ ... $
  \ENDIF
\end{algorithmic}

En este ejemplo \texttt{esPositivo} es un predicado que es evaluado a falso si $ n $ no es positivo y a verdadero si lo es.

La codificación de valores de verdad y operaciones booleanas es común incluso en lenguajes de programación populares, por ejemplo en C, el tipo \texttt{bool} es codificado como un entero, en donde falso es 0 y verdadero cualquier otro entero, a su vez, los enteros son codificados usualmente como secuencias de 32 bits en complemento a dos. Por lo tanto, si <<esPositivo>> fuera una función de C: \texttt{esPositivo(8)} sería evaluado a 1 y \texttt{esPositivo(-8)} sería evaluado a 0.

Al igual que el cálculo $ λ $, otras teorías que fundamentan las ciencias de la computación también carecen de expresiones y operaciones booleanas. En el caso de la máquina de Turing los cambios de estado en la ejecución de un programa se determinan a partir de su función de transición y predicados simples de igualdad entre símbolos del alfabeto de cinta se realizan en un paso, sin embargo, predicados mas complejos requieren ser codificados con estados, transiciones y anotaciones en su cinta.

\subsection{Valores de verdad}
\label{sec:valores-de-verdad}

En el álgebra booleana, los valores de las expresiones son falso y verdadero. El nombre de estos valores no es de relevancia y usualmente falso se representa como 0 y verdadero como 1. El aspecto importante de estos valores es que son distintos y si un valor $ x $ no es uno, entonces es el otro.

Podemos ignorar la representación concreta de estos valores y pensar en una situación hipotética: Una persona omnisciente y muda llamada $ P $ puede decirme si una oración que le digo es falsa o verdadera dándole una manzana y una pera; si me regresa la manzana significa que la oración es verdadera y si me regresa la pera significa que la oración es falsa. En este planteamiento irreal e hipotético, no fué necesario conocer la estructura de la verdad y la falsedad, solo fué necesario tener a alguien que tomara una desición (en este caso $ P $) y proveer dos objetos que podemos distinguir entre sí (en este caso la manzana y la pera). Las desiciones de esta persona pueden ser los conceptos de falso y verdadero si nunca podemos conocer los valores booleanos.

Detrás del concepto de falso y verdadero, está el concepto de \emph{desición}, la codificación que se desarrolla está basada en este concepto y aparece en \cite[p.~133]{Barendregt:Bible}.

Supongamos que $ P $ es un término $ λ $ el cual puede ser aplicado a una oración $ O $, al $ β $-reducir $ (P\, O) $ se obtiene una decisión $ D $ la cual al ser aplicada a dos términos $ λ $ $ M $ y $ N $ se $ β $-reduce a $ M $ si la oración $ O $ es verdadera y a $ M $ si es falsa:
\[ P\, O \reduce{β} D, \]
\[ D\, M\, N \reduce{β} \begin{cases} M & \text{si $ O $ es verdadera}\\ N & \text{si $ O $ es falsa}\end{cases} .\]
Para fines prácticos no es necesario saber cómo es $ P $ ni $ O $, lo importante es que cuando $ O $ es cierta, $ D $ eligirá $ M $ y si $ O $ es falsa, eligirá $ N $. Por lo tanto, $ (P\, O) = D $ es un término $ λ $ de la forma
\[ λx\, y.Q \]
Si $ D $ es una desición tomada por que $ O $ es verdadera, podemos asegurar que $ (D\, M\, N) = M $, por lo tanto:
\[ D \synteq λx\, y.x \]
Si $ D $ es una desición tomada por que $ O $ es falsa, podemos asegurar que $ (D\, M\, N) = N $, por lo tanto:
\[ D \synteq λx\, y.y \]
Teniendo los términos $ λ $ que representan la desición de $ P $ ante una oración falsa y ante una oración verdadera, se puede considerar que estos términos representan el concepto de falso y verdadero.

\begin{defn}[Valores de verdad]
  \label{defn:valores-verdad}
  El concepto de falso y verdadero es codificado en el cálculo $ λ $ como los términos $ \bs{T} $ y $ \bs{F} $ respectivamente.
  \begin{align*}
    \bs{T} &\synteq λx\, y.x & \bs{F} &\synteq λx\, y.y
  \end{align*}
\end{defn}

Utilizar $ \bs{T} $ y $ \bs{F} $ en términos $ λ $ es similar a imitar a $ P $ y determinar cuando $ O $ es verdadera o falsa. Esto es debido a que se pueden plantear predicados que sean conceptualmente ilógicos, por ejemplo, si <<esPositivo>> se define de tal manera que sin importar en que valor sea evaluado siempre resulte en falso, los programas que se escriban no van a funcionar suponiendo que <<esPositivo>> calcula lo que debe de calcular, sin embargo lo importante de codificar el álgebra booleana es poder manipular los valores de falso y verdadero, no representar un término $ P $ que determine verdades absolutas.

\subsection{Expresiones booleanas}
\label{sec:expresiones-booleanas}

Las expresiones booleanas se conforman de operaciones y valores de verdad. Las operaciones más básicas son la conjunción, la disyunción y la negación, también llamadas $ AND $, $ OR $, $ NOT $ y denotadas $ \land $, $ \lor $ y $ \lnot $ respectivamente.

La conjunción y la disyunción son operaciones binarias definidas en

\[ \{ \mathrm{falso},\ \mathrm{verdadero} \}^{2} \to \{ \mathrm{falso},\ \mathrm{verdadero} \} \]

y la negación es una operación unaria definida en

\[ \{ \mathrm{falso},\ \mathrm{verdadero} \} \to \{ \mathrm{falso},\ \mathrm{verdadero} \}. \]

Las tablas de verdad en la \autoref{tab:and-or-not} establecen los resultados de estas tres operaciones para cada valor en su dominio.

\begin{table}[!htbp]
  \centering
  \small
  \begin{tabular}{|c|c|c|c|}
    \hline
    $ x $ & $ y $ & $ x \land y $ & $ x \lor y $ \\ [0.5ex]
    \hline\hline
    falso & falso & falso & falso \\
    falso & verdadero & falso & verdadero \\
    verdadero & falso & falso & verdadero \\
    verdadero & verdadero & verdadero & verdadero \\
    \hline
  \end{tabular}
  \hfill
  \begin{tabular}{|c|c|}
    \hline
    $ x $ & $ \lnot x $ \\ [0.5ex]
    \hline\hline
    falso & verdadero  \\
    verdadero & falso \\
    \hline
  \end{tabular}
  \caption{Tablas de verdad para $ \land $, $ \lor $ y $ \lnot $}
  \label{tab:and-or-not}
\end{table}

En el álgebra booleana, las expresiones se escriben en notación de infijo, utilizan paréntesis para agrupar expresiones y cuando los paréntesis son omitidos la negación tiene mayor presedencia que la conjunción y la conjunción tiene mayor presedencia que la disyunción, por ejemplo:

\[ \mathrm{verdadero} \land \mathrm{falso} \lor \lnot \mathrm{falso} \]
\[ \lnot (\mathrm{falso} \lor \mathrm{falso}) \]
\[ \mathrm{verdadero} \land (\mathrm{falso} \lor \mathrm{falso}) \]

Esta notación es conveniente para escribir expresiones booleanas de manera concisa, pero es únicamente una conveniencia sintáctica del álgebra booleana. La codificación que se desarrolla de las operaciones seguirá las convenciones sintácticas del cálculo $ λ $, por ejemplo, suponiendo que $ \bs{\land} $, $ \bs{\lor} $, $ \bs{\lnot} $ son términos $ λ $, las expresiones mencionadas escribirían con notación de prefijo:
\[ \bs{\lor} (\bs{\land}\, \bs{T}\, \bs{F}) \bs{F} \]
\[ \bs{\lnot} (\bs{\lor}\, \bs{F}\, \bs{F}) \]
\[ \bs{\land}\, \bs{T} (\bs{\lor}\, \bs{F}\, \bs{F}) \]

Al igual que los valores de verdad, las operaciones básicas son codificadas como abstracciones del cálculo $ λ $. Hay varias metodologías para derivar términos $ λ $ para las operaciones booleanas a partir de $ \bs{T} $ y $ \bs{F} $, en esta sección se abordarán dos:
\begin{itemize}
\item Combinar valores de verdad
\item Programar las operaciones
\end{itemize}
La primera metodología parte de la observación de que la codificación de falso y verdadero son abstracciones, por lo tanto, es posible $ β $-reducirlas al aplicarlas a otros términos; se explora la clase de términos $ λ $ en $ \{ \bs{T},\ \bs{F} \}^{+} $.

La segunda metodología presenta la construcción del operador condicional, a partir del cual se derivan las operaciones booleanas como si fueran programas de computadora.

\subsubsection{Combinaciones de valores de verdad}
\label{sec:combinacion-valores}

Una manera de obtener términos $ λ $ a partir de $ \bs{F} $ y $ \bs{T} $ es $ β $-reducir combinaciones de aplicaciones entre estos valores. En la \autoref{tab:verdad-pares} se muestran los términos obtenidos al reducir combinaciones de dos valores de verdad.

\begin{table}[!htbp]
  \centering
  \begin{tabular}{|c||l|}
    \hline
    $ \bs{F}\, \bs{F} $ & $ (λx\, y.y)\, \bs{F} \reduce{β} λy.y \synteq \bs{I} $ \\
    \hline
    $ \bs{F}\, \bs{T} $ & $ (λx\, y.y)\, \bs{T} \reduce{β} λy.y \synteq \bs{I} $ \\
    \hline
    $ \bs{T}\, \bs{F} $ & $ (λx\, y.x)\, \bs{F} \reduce{β} λy.\bs{F} \synteq \bs{K}\, \bs{F} $ \\
    \hline
    $ \bs{T}\, \bs{T} $ & $ (λx\, y.x)\, \bs{T} \reduce{β} λy.\bs{T} \synteq \bs{K}\, \bs{T} $ \\
    \hline
  \end{tabular}
  \caption{Posibles combinaciones de valores de verdad por pares.}
  \label{tab:verdad-pares}
\end{table}

En las reducciones de la \autoref{tab:verdad-pares} se pueden observar cuatro términos, a partir de estos se puede descubrir la operación de negación:

\begin{itemize}
\item $ (\bs{F}\, \bs{F}) $ se reduce a la abstracción identidad, esto significa que para cualquier término $ M \in Λ $
  \[ \bs{λ} \vdash (\bs{F}\, \bs{F}\, M) = M \]
\item Al igual que la primera reducción $ (\bs{F}\, \bs{T}) $ se reduce a $ \bs{I} $, por lo tanto se concluye que para cualesquiera términos $ M \in Λ $, $ N \in \{ \bs{F},\ \bs{T} \} $
  \[ \bs{λ} \vdash (\bs{F}\, N\, M) = M \]
\item $ (\bs{T}\, \bs{F}) $ se reduce a la abstracción constante de $ \bs{F} $, esto significa que para cualquier término $ M \in Λ $
  \[ \bs{λ} \vdash (\bs{T}\, \bs{F}\, M) = \bs{F} \]
\item Al igual que la tercera reducción $ (\bs{T}\, \bs{T}) $ se reduce a $ (\bs{K}\, \bs{T}) $, por lo tanto se concluye que para cualesquiera términos $ M \in Λ $, $ N \in \{ \bs{F},\ \bs{T} \} $
  \[ \bs{λ} \vdash (\bs{T}\, N\, M) = N \]
\end{itemize}

Debido a las reducciones mostradas en la \autoref{tab:verdad-pares} se puede analizar que a partir de un témino $ \bs{F} $, se puede obtener $ \bs{T} $ al reducir $ (\bs{F}\, N\, \bs{T}) $ y que a partir de un término $ \bs{T} $, se puede obtener $ \bs{F} $ al reducir $ (\bs{T}\, \bs{F}\, M) $. Considerando que $ N \synteq \bs{F} $ y $ M \synteq \bs{T} $ las reducciones serían:
\[ \bs{F}\, \bs{F}\, \bs{T} \reduce{β} \bs{T} \]
\[ \bs{T}\, \bs{F}\, \bs{T} \reduce{β} \bs{F} \]

Si se considera que $ P \in \{ \bs{F},\ \bs{T} \} $
\[ P\, \bs{F}\, \bs{T} \reduce{β} \bs{\lnot}\, P \]

\begin{rem}[Sobre la $ β $-reducción]
  En el tratamiento de la codificación del álgebra booleana en el cálculo $ λ $, cuando se $ β $-reducen términos $ λ $ que tienen como subtérminos valores que suponemos son $ \bs{F} $ o $ \bs{T} $ se extiende la teoría $ \bs{λ} $ con la siguiente ecuación:
  \begin{align*}
    P\, \bs{T}\, \bs{F} &= P && \text{si $ P \in \{ \bs{F},\ \bs{T} \} $}
  \end{align*}
\end{rem}
\begin{defn}[Operación de negación]
  \label{defn:negacion}
  El término $ λ $ $ \bs{\lnot} \synteq (λp.p\, \bs{F}\, \bs{T}) $ se reduce a $ \bs{T} $ cuando es aplicado a $ \bs{F} $ y viceversa
  \begin{align*}
    \bs{\lnot}\, \bs{F} &\synteq (λp.p\, \bs{F}\, \bs{T})\, \bs{F} \\
                        &\contract{β} \bs{F}\, \bs{F}\, \bs{T} \\
                        &\reduce{β} \bs{T} \\
    \bs{\lnot}\, \bs{T} &\synteq (λp.p\, \bs{F}\, \bs{T})\, \bs{T} \\
                        &\contract{β} \bs{T}\, \bs{F}\, \bs{T} \\
                        &\reduce{β} \bs{F}
  \end{align*}
\end{defn}

Las reducciones de la \autoref{tab:verdad-pares} se pueden aplicar a $ \bs{F} $ y $ \bs{T} $ para obtener todas las posibles combinaciones de aplicaciones de valores de verdad de la forma $ ((P\, M) N) $, en la \autoref{tab:verdad-tripletas} se muestran las reducciones de las nuevas aplicaciones.

\begin{table}[!htbp]
  \centering
  \begin{tabular}{|c||l|}
    \hline
    $ \bs{F}\, \bs{F}\, \bs{F} $ & $ \bs{I}\, \bs{F} \reduce{β} \bs{F} $ \\
    \hline
    $ \bs{F}\, \bs{F}\, \bs{T} $ & $ \bs{I}\, \bs{T} \reduce{β} \bs{T} $ \\
    \hline
    $ \bs{F}\, \bs{T}\, \bs{F} $ & $ \bs{I}\, \bs{F} \reduce{β} \bs{F} $ \\
    \hline
    $ \bs{F}\, \bs{T}\, \bs{T} $ & $ \bs{I}\, \bs{T} \reduce{β} \bs{T} $ \\
    \hline
    $ \bs{T}\, \bs{F}\, \bs{F} $ & $ \bs{K}\, \bs{F}\, \bs{F} \reduce{β} \bs{F} $ \\
    \hline
    $ \bs{T}\, \bs{F}\, \bs{T} $ & $ \bs{K}\, \bs{F}\, \bs{T} \reduce{β} \bs{F} $ \\
    \hline
    $ \bs{T}\, \bs{T}\, \bs{F} $ & $ \bs{K}\, \bs{T}\, \bs{F} \reduce{β} \bs{T} $ \\
    \hline
    $ \bs{T}\, \bs{T}\, \bs{T} $ & $ \bs{K}\, \bs{T}\, \bs{T} \reduce{β} \bs{T} $ \\
    \hline
  \end{tabular}
  \caption{Posibles combinaciones de valores de verdad con asociación a la izquierda.}
  \label{tab:verdad-tripletas}
\end{table}

Al observar la \autoref{tab:verdad-tripletas}, se distinguen algúnos patrones en los resultados de las reducciones, por ejemplo, si $ P $ es un valor de verdad cualquiera, $ (P\, \bs{F}\, \bs{F}) $ se reduce a $ \bs{F} $ y $ (P\, \bs{T}\, \bs{T}) $ se reduce a $ \bs{T} $, las combinaciones mas interesantes se presentan en los renglones 2, 3, 6 y 7.

En búsqueda de las operaciones binarias de conjunción y disyunción se desarrollan tablas de verdad con las posibles combinaciones de dos términos $ P, Q \in \{ \bs{F},\ \bs{T} \} $. La cantidad de combinaciones de estos valores es $ 2 \times \binom 3 2 = 2 \times \frac{3!}{2!} = 6 $ y son
\[ (P\, Q\, \bs{F}) ,\ (P\, Q\, \bs{T}) ,\ (P\, \bs{F}\, Q) ,\ (P\, \bs{T}\, Q) ,\ (\bs{F}\, P\, Q) ,\ (\bs{T}\, P\, Q) \]
Las tablas de verdad de estas combinaciones intercambiando las posiciones de $ P $ y $ Q $ serían las mismas ya que ambos términos toman los valores de falso y verdadero en las tablas de verdad. En la \autoref{tab:verdad-pq} se muestran estas tablas.


\begin{table}[!htbp]
  \centering
  \begin{tabular}{|c|c||c|c|c|c|c|c|}
    \hline
    $ P $ & $ Q $ & $ P\, Q\, \bs{F} $ & $ P\, Q\, \bs{T} $ & $ P\, \bs{F}\, Q $ & $ P\, \bs{T}\, Q $ & $ \bs{F}\, P\, Q $ & $ \bs{T}\, P\, Q $ \\ [0.5ex]
    \hline
    \hline
    $ \bs{F} $ & $ \bs{F} $ & $ \bs{F} $ & $ \bs{T} $ & $ \bs{F} $ & $ \bs{F} $ & $ \bs{F} $ & $ \bs{F} $ \\
    $ \bs{F} $ & $ \bs{T} $ & $ \bs{F} $ & $ \bs{T} $ & $ \bs{T} $ & $ \bs{T} $ & $ \bs{T} $ & $ \bs{F} $ \\
    $ \bs{T} $ & $ \bs{F} $ & $ \bs{F} $ & $ \bs{F} $ & $ \bs{F} $ & $ \bs{T} $ & $ \bs{F} $ & $ \bs{T} $ \\
    $ \bs{T} $ & $ \bs{T} $ & $ \bs{T} $ & $ \bs{T} $ & $ \bs{F} $ & $ \bs{T} $ & $ \bs{T} $ & $ \bs{T} $ \\
    \hline
  \end{tabular}
  \caption{Tablas de verdad considerando dos variables $ P $ y $ Q $ en aplicaciones de tres términos}
  \label{tab:verdad-pq}
\end{table}

Las columnas de la combinación $ (P\, Q\, \bs{F}) $ y $ (P\, \bs{T}\, Q) $ de la \autoref{tab:verdad-pq} corresponden a la operación de conjunción y disyunción respectivamente, como aparecen en la \autoref{tab:and-or-not}. Las otras combinaciones corresponden a operaciones no básicas del álgebra booleana: $ (P\, Q\, \bs{T}) $ es la implicación material; $ (P\, \bs{F}\, Q) $ es la no implicación inversa; $ (\bs{F}\, P\, Q) $ es la proyección de $ Q $; y $ (\bs{T}\, P\, Q) $ es la proyección de $ P $.

Ya que  $ \bs{λ} \vdash (P\, Q\, \bs{F}) = (\bs{\land}\, P\, Q) $ y $ \bs{λ} \vdash (P\, \bs{T}\, Q) = (\bs{\lor}\, P\, Q) $, se construyen los términos $ \bs{\land} $ y $ \bs{\lor} $ abstrayendo a $ P $ y $ Q $ de las igualdades.

\begin{defn}[Operación de conjunción]
  \label{defn:conjuncion}
  El término $ λ $ que representa la conjunción es
  \[ \bs{\land} \synteq λp\, q.p\, q\, \bs{F} \]
  y cumple las siguientes propiedades de $ β $-reducción al ser aplicada a valores de verdad:
  \begin{align*}
    \bs{\land}\, \bs{F}\, \bs{F} &\synteq (λp\, q.p\, q\, \bs{F})\, \bs{F}\, \bs{F} \reduce{β} \bs{F}\, \bs{F}\, \bs{F} \reduce{β} \bs{F} \\
    \bs{\land}\, \bs{F}\, \bs{T} &\synteq (λp\, q.p\, q\, \bs{F})\, \bs{F}\, \bs{T} \reduce{β} \bs{F}\, \bs{T}\, \bs{F} \reduce{β} \bs{F} \\
    \bs{\land}\, \bs{T}\, \bs{F} &\synteq (λp\, q.p\, q\, \bs{F})\, \bs{T}\, \bs{F} \reduce{β} \bs{T}\, \bs{F}\, \bs{F} \reduce{β} \bs{F} \\
    \bs{\land}\, \bs{T}\, \bs{T} &\synteq (λp\, q.p\, q\, \bs{F})\, \bs{T}\, \bs{T} \reduce{β} \bs{T}\, \bs{T}\, \bs{F} \reduce{β} \bs{T}
  \end{align*}
\end{defn}

\begin{defn}[Operación de disyunción]
  \label{defn:disyuncion}
  El término $ λ $ que representa la disyunción es
  \[ \bs{\lor} \synteq λp\, q.p\, \bs{T}\, q \]
  y cumple las siguientes propiedades de $ β $-reducción al ser aplicada a valores de verdad:
  \begin{align*}
    \bs{\lor}\, \bs{F}\, \bs{F} &\synteq (λp\, q.p\, \bs{T}\, q) \bs{F}\, \bs{F} \reduce{β} \bs{F}\, \bs{T}\, \bs{F} \reduce{β} \bs{F} \\
    \bs{\lor}\, \bs{F}\, \bs{T} &\synteq (λp\, q.p\, \bs{T}\, q) \bs{F}\, \bs{T} \reduce{β} \bs{F}\, \bs{T}\, \bs{T} \reduce{β} \bs{T} \\
    \bs{\lor}\, \bs{T}\, \bs{F} &\synteq (λp\, q.p\, \bs{T}\, q) \bs{T}\, \bs{F} \reduce{β} \bs{T}\, \bs{T}\, \bs{F} \reduce{β} \bs{T} \\
    \bs{\lor}\, \bs{T}\, \bs{T} &\synteq (λp\, q.p\, \bs{T}\, q) \bs{T}\, \bs{T} \reduce{β} \bs{T}\, \bs{T}\, \bs{T} \reduce{β} \bs{T}
  \end{align*}
\end{defn}

Esta metodología para encontrar operaciones del álgebra booleana, aplicando los términos codificados de los valores de verdad, es tediosa pero hasta cierto grado efectiva. Como en los casos de las operaciones no básicas mostradas en la \autoref{tab:verdad-pq}, operaciones del álgebra booleana pueden ser ``descubiertas'' y no construidas. Ya que la negación, la conjunción y la disyunción fueron descubiertas con este método, cualquier operación booleana eventualmente será encontrada como combinación de valores de verdad. Sin embargo, descubrir la codificación de una operación booleana complicada utilizando este método es un proceso muy tardado.

\subsubsection{Programación de operaciones booleanas}
\label{sec:programacion-operaciones}

Otra metodología que permite construir las operaciones booleanas como términos $ λ $ es la de partir de un algoritmo que las describa. Usualmente las operaciones booleanas no son definidas como procedimientos, si no como operaciones primitivas del lenguaje utilizado para describirlos.

Consideremos dos términos $ M $ y $ N $. Ya que $ (\bs{T}\, M\, N) \reduce{β} M $ y $ (\bs{F}\, M\, N) \reduce{β} N $, si $ M \reduce{β} M' $ y $ N \reduce{β} N' $, entonces
\[ \bs{T}\, M\, N \reduce{β} M' \]
\[ \bs{F}\, M\, N \reduce{β} N' \]

Es decir, si $ P \in \{ \bs{F},\ \bs{T} \} $:
\[ P\, M\, N \reduce{β} \begin{cases} M' & P \synteq \bs{T} \\ N' & P \synteq \bs{F} \end{cases} \]

Esta aplicación de un valor de verdad a dos términos $ λ $ cualquiera permite capturar el concepto de una expresión o sentencia condicional, usualmente llamada en los lenguajes de programación como sentencia \texttt{if-then-else}.

\begin{defn}[Expresión condicional]
  \label{defn:condicional}
  El término $ λ $ que representa a la expresión condicional es
  \[ \bs{\prec} \synteq λp\, m\, n.p\, m\, n \]
  Y si $ P $ es un valor de verdad, entonces
  \begin{align*}
    \bs{\prec}\, P\, M\, N &\synteq (λp\, m\, n.p\, m\, n)\, P\, M\, N \\
                           &\reduce{β} P\, M\, N
  \end{align*}
  Un programa de la forma
  \begin{algorithmic}
    \IF{$ P $}
    \STATE $ M $
    \ELSE
    \STATE $ N $
    \ENDIF
  \end{algorithmic}
  Puede ser traducido a $ (\bs{\prec}\, P\, M\, N) $
\end{defn}

Consideremos la siguiente definición en pseudocódigo de la operación de negación:
\begin{algorithm}
  \caption{Negación de $ p $}
  \label{alg:negacion}
  \begin{algorithmic}
    \REQUIRE $ p \in \{ \mathrm{falso},\ \mathrm{verdadero} \} $
    \ENSURE $ \lnot p $
    \IF{$ p $}
    \RETURN falso
    \ELSE
    \RETURN verdadero
    \ENDIF
  \end{algorithmic}
\end{algorithm}
El pseudocódigo se traduce al cálculo $ λ $ como
\[ \bs{\lnot} \synteq λp.\bs{\prec}\, p\, \bs{F}\, \bs{T} \]
El cuerpo de la abstracción puede ser $ β $-reducido para obtener el término de la \autoref{defn:negacion}
\begin{align*}
  λp.\bs{\prec}\, p\, \bs{F}\, \bs{T} &\synteq λp.(λp\, m\, n.p\, m\, n)\, p\, \bs{F}\, \bs{T} \\
                                      &\reduce{β} λp.p\, \bs{F}\, \bs{T}
\end{align*}

Para la operación de conjunción, se considera el siguiente pseudocódigo:
\begin{algorithm}
  \caption{Conjunción de $ p_{1} $ y $ p_{2} $}
  \label{alg:conjuncion}
  \begin{algorithmic}
    \REQUIRE $ p_{1}, p_{2} \in \{ \mathrm{falso},\ \mathrm{verdadero} \} $
    \ENSURE $ p_{1} \land p_{2} $
    \IF{$ p_{1} $}
    \IF{$ p_{2} $}
    \RETURN verdadero
    \ELSE
    \RETURN false
    \ENDIF
    \ELSE
    \RETURN falso
    \ENDIF
  \end{algorithmic}
\end{algorithm}

Traducido al cálculo $ λ $ como
\[ \bs{\land} \synteq λp_{1}\, p_{2}.\bs{\prec}\, p_{1}\, (\bs{\prec}\, p_{2}\, \bs{T}\, \bs{F})\, \bs{F} \]
Al $ β $-reducir el cuerpo de la abstracción se obtiene el término de la \autoref{defn:conjuncion}
\begin{align*}
  λp_{1}\, p_{2}.\bs{\prec}\, p_{1}\, (\bs{\prec}\, p_{2}\, \bs{T}\, \bs{F})\, \bs{F}
  &\synteq λp_{1}\, p_{2}.(λp\, m\, n.p\, m\, n)\, p_{1}\, ((λp\, m\, n.p\, m\, n)\, p_{2}\, \bs{T}\, \bs{F})\, \bs{F} \\
  &\reduce{β} λp_{1}\, p_{2}.p_{1}\, ((λp\, m\, n.p\, m\, n)\, p_{2}\, \bs{T}\, \bs{F})\, \bs{F} \\
  &\reduce{β} λp_{1}\, p_{2}.p_{1}\, (p_{2}\, \bs{T}\, \bs{F})\, \bs{F} \\
  &=_{\bs{λ}} λp_{1}\, p_{2}.p_{1}\, p_{2}\, \bs{F}
\end{align*}

De igual manera, considerando el siguiente pseudocódigo de la operación de disyunción:
\begin{algorithm}
  \caption{Disyunción de $ p_{1} $ y $ p_{2} $}
  \label{alg:disyuncion}
  \begin{algorithmic}
    \REQUIRE $ p_{1}, p_{2} \in \{ \mathrm{falso},\ \mathrm{verdadero} \} $
    \ENSURE $ p_{1} \lor p_{2} $
    \IF{$ p_{1} $}
    \RETURN verdadero
    \ELSE
    \IF{$ p_{2} $}
    \RETURN verdadero
    \ELSE
    \RETURN falso
    \ENDIF
    \ENDIF
  \end{algorithmic}
\end{algorithm}

Se traduce al cálculo $ λ $ como
\[ \bs{\lor} \synteq λp_{1}\, p_{2}.\bs{\prec}\, p_{1}\, \bs{T}\, (\bs{\prec}\, p_{2}\, \bs{T}\, \bs{F}) \]
Y al $ β $-reducir el cuerpo de la abstracción se obtiene el término de la \autoref{defn:disyuncion}

\begin{align*}
  λp_{1}\, p_{2}.\bs{\prec}\, p_{1}\, \bs{T}\, (\bs{\prec}\, p_{2}\, \bs{T}\, \bs{F})
  &\synteq λp_{1}\, p_{2}.(λp\, m\, n.p\, m\, n)\, p_{1}\, \bs{T}\, ((λp\, m\, n.p\, m\, n)\, p_{2}\, \bs{T}\, \bs{F}) \\
  &\reduce{β} λp_{1}\, p_{2}.p_{1}\, \bs{T}\, ((λp\, m\, n.p\, m\, n)\, p_{2}\, \bs{T}\, \bs{F}) \\
  &\reduce{β} λp_{1}\, p_{2}.p_{1}\, \bs{T}\, (p_{2}\, \bs{T}\, \bs{F}) \\
  &=_{\bs{λ}} λp_{1}\, p_{2}.p_{1}\, \bs{T}\, p_{2}
\end{align*}

Utilizando esta técnica, se puede obtener el término $ λ $ para una operación a partir del pseudocódigo basado en valores de verdad y la sentencia \verb!if-then-else!. Teniendo estos resultados resulta natural, generalizar el pseudocódigo para construir un término $ λ $ que a partir de la tabla de verdad de una operación booleana binaria, resulte en la abstracción que codifica la operación.

\begin{defn}[Traducción de operaciones booleanas binarias]
  \label{defn:op-bool-bin-lambda}
  Sea $ \bs{\odot} $ una operación booleana binaria con la siguiente tabla de verdad

  \begin{center}
    \begin{tabular}{|c|c||c|}
      \hline
      $ P $ & $ Q $ & $ P \bs{\odot} Q $ \\ [0.5ex]
      \hline\hline
      $ \bs{F} $ & $ \bs{F} $ & $ x_{1} $ \\
      \hline
      $ \bs{F} $ & $ \bs{T} $ & $ x_{2} $ \\
      \hline
      $ \bs{T} $ & $ \bs{F} $ & $ x_{3} $ \\
      \hline
      $ \bs{T} $ & $ \bs{T} $ & $ x_{4} $ \\
      \hline
    \end{tabular}
  \end{center}

  El procedimiento generalizado es

  \begin{algorithm}
    \caption{Operación booleana $ \odot $ dado $ x_{1} $, $ x_{2} $, $ x_{3} $, $ x_{3} $}
    \label{alg:bool-bin-gen}
    \begin{algorithmic}
      \REQUIRE $ p_{1}, p_{2} \in \{ \mathrm{falso},\ \mathrm{verdadero} \} $
      \ENSURE Valor $ x_{i} $ de la tabla de verdad
      \IF{$ p_{1} $}
      \IF{$ p_{2} $}
      \RETURN $ x_{4} $
      \ELSE
      \RETURN $ x_{3} $
      \ENDIF
      \ELSE
      \IF{$ p_{2} $}
      \RETURN $ x_{2} $
      \ELSE
      \RETURN $ x_{1} $
      \ENDIF
      \ENDIF
    \end{algorithmic}
  \end{algorithm}

  Y la traducción al cálculo $ λ $ es
  \[ λx_{1}\, x_{2}\, x_{3}\, x_{4}.(λp_{1}\, p_{2}.(\bs{\prec}\, p_{1} (\bs{\prec}\, p_{2}\, x_{4}\, x_{3}) (\bs{\prec}\, p_{2}\, x_{2}\, x_{1}))) \]
  
\end{defn}

Las operaciones booleanas binarias \emph{NAND} y \emph{NOR} conforman los conjuntos unitarios $ \{ \mathrm{NAND} \} $ y $ \{ \mathrm{NOR} \} $ los cuales son conjuntos funcionalmene completos, es decir, únicamente con la operación NAND se puede emular cualquier operación booleana y únicamente con la operación NOR se puede emular cualquier operación booleana.

La operación \emph{NAND} se denota $ P \uparrow Q $ y tiene la siguiente tabla de verdad
\begin{center}
  \begin{tabular}{|c|c||c|}
    \hline
    $ P $ & $ Q $ & $ P \uparrow Q $ \\ [0.5ex]
    \hline\hline
    $ \bs{F} $ & $ \bs{F} $ & $ \bs{T} $ \\
    \hline
    $ \bs{F} $ & $ \bs{T} $ & $ \bs{T} $ \\
    \hline
    $ \bs{T} $ & $ \bs{F} $ & $ \bs{T} $ \\
    \hline
    $ \bs{T} $ & $ \bs{T} $ & $ \bs{F} $ \\
    \hline
  \end{tabular}
\end{center}
Con el proceso de traducción mostrado en la \autoref{defn:op-bool-bin-lambda}, el término $ \bs{\uparrow} $ que codifica la operación NAND sería
\begin{align*}
  \bs{\uparrow}
  &\synteq λp_{1}\, p_{2}. \bs{\prec}\, p_{1}\, (\bs{\prec}\, p_{2}\, \bs{F}\, \bs{T})\, (\bs{\prec}\, p_{2}\, \bs{T}\, \bs{T}) \\
  &\reduce{β} λp_{1}\, p_{2}.p_{1}\, (p_{2}\, \bs{F}\, \bs{T})\, \bs{T}
\end{align*}

La operación \emph{NOR} se denota $ P \downarrow Q $ y tiene la siguiente tabla de verdad
\begin{center}
  \begin{tabular}{|c|c||c|}
    \hline
    $ P $ & $ Q $ & $ P \downarrow Q $ \\ [0.5ex]
    \hline\hline
    $ \bs{F} $ & $ \bs{F} $ & $ \bs{T} $ \\
    \hline
    $ \bs{F} $ & $ \bs{T} $ & $ \bs{F} $ \\
    \hline
    $ \bs{T} $ & $ \bs{F} $ & $ \bs{F} $ \\
    \hline
    $ \bs{T} $ & $ \bs{T} $ & $ \bs{F} $ \\
    \hline
  \end{tabular}
\end{center}
Usando el mismo proceso de traducción que con la operación NAND, se obtiene
\begin{align*}
  \bs{\downarrow}
  &\synteq λp_{1}\, p_{2}. \bs{\prec}\, p_{1} (\bs{\prec}\, p_{2}\, \bs{F}\, \bs{F}) (\bs{\prec}\, p_{2}\, \bs{F}\, \bs{T}) \\
  &\reduce{β} λp_{1}\, p_{2}.p_{1}\, \bs{F} (p_{2}\, \bs{F}\, \bs{T})
\end{align*}

Un aspecto interesante de este método de traducción de operaciones booleanas es que se puede adaptar para operaciones $ n $-árias. Un bosquejo de la forma de estas generalizaciones es
\begin{center}
  \begin{tikzpicture}[level/.style={sibling distance=100mm/#1, level distance=10mm}]
    \node (args1) {$ λx_{1}\, ...\, x_{2^{n}} $}
    child {
      node (args2) {$ λp_{1}\, ...\, p_{n} $}
      child {
        node (p1) {$ \bs{\prec}\, p_{1} $}
        child {
          node (p2a) {$ \bs{\prec}\, p_{2} $}
          child {
            node (dots1) {$ ... $}
            child {
              node (pna) {$ \bs{\prec}\, p_{n} $}
              child {
                node (x2n) {$ x_{2^{n}} $}
              }
              child {
                node (x2n1) {$ x_{2^{n}-1} $}
              }
            }
            child {
              node (dots3) {$ ... $}
            }
          }
          child {
            node (dots2) {$ ... $}
          }
        }
        child {
          node (p2b) {$ \bs{\prec}\, p_{2} $}
          child {
            node (dots4) {$ ... $}
          }
          child {
            node (dots5) {$ ... $}
            child {
              node (dots6) {$ ... $}
            }
            child {
              node (pnb) {$ \bs{\prec}\, p_{n} $}
              child {
                node (x2) {$ x_{2} $}
              }
              child {
                node (x1) {$ x_{1} $}
              }
            }
          }
        }
      }
    };
  \end{tikzpicture}
\end{center}

\subsection{Extensiones al álgebra booleana}
\label{sec:boolean-extensiones}

Conociendo el proceso de codificación del álgebra booleana en el cálculo $ λ $, resulta simple adaptar la codificación.

Consideremos el caso en donde, además de tener los valores de falso y verdadero, se desea incorporar un valor ``desconocido'' utilizado para representar un valor que no es ni falso, ni verdadero. La interpretación de estos valores es similar a la \autoref{defn:valores-verdad}, pero en lugar de decidir sobre dos términos, se decide sobre tres.

\begin{defn}[Valores de álgebra trivalente]
  La codificación en términos $ λ $ de los valores de ésta álgebra trivalente son
  \begin{align*}
    \bs{T} &\synteq λx\, y\, z.x \\
    \bs{F} &\synteq λx\, y\, z.y \\
    \bs{U} &\synteq λx\, y\, z.z 
  \end{align*}
\end{defn}

Al igual que en la codificación bivalente, se puede codificar un término $ \bs{\prec_{3}} $, similar a $ \bs{\prec} $ de la \autoref{defn:condicional} pero con tres ramificaciones
\begin{defn}[Condicional trivalente]
  \[ \bs{\prec_{3}} \synteq λp\, m\, n\, o.p\, m\, n\, o \]
  De tal manera que, si $ P \in \{ \bs{T},\ \bs{F},\ \bs{U} \} $
  \[ (\bs{\prec_{3}}\, P\, M\, N\, O) \reduce{β} \begin{cases} M & P \synteq \bs{T}; \\ N & P \synteq \bs{F}; \\ O & P \synteq \bs{U}. \end{cases} \]
\end{defn}

Sea $ \odot $ una operación trivalente binaria con la siguiente tabla de valores
\begin{center}
  \begin{tabular}{|c|c||c|}
    \hline
    $ P $ & $ Q $ & $ P \odot Q $ \\ [0.5ex] \hline\hline
    $ \bs{T} $ & $ \bs{T} $ & $ x_{1} $ \\ \hline
    $ \bs{T} $ & $ \bs{F} $ & $ x_{2} $ \\ \hline
    $ \bs{T} $ & $ \bs{U} $ & $ x_{3} $ \\ \hline
    $ \bs{F} $ & $ \bs{T} $ & $ x_{4} $ \\ \hline
    $ \bs{F} $ & $ \bs{F} $ & $ x_{5} $ \\ \hline
    $ \bs{F} $ & $ \bs{U} $ & $ x_{6} $ \\ \hline
    $ \bs{U} $ & $ \bs{T} $ & $ x_{7} $ \\ \hline
    $ \bs{U} $ & $ \bs{F} $ & $ x_{8} $ \\ \hline
    $ \bs{U} $ & $ \bs{U} $ & $ x_{9} $ \\ \hline
  \end{tabular}
\end{center}

El procedimiento en pseudocódigo que la describe se muestra en el \autoref{alg:op-bin-gen-2} y es traducido al cálculo $ λ $ como
\[ λx_{1}\, x_{2}\, x_{3}\, x_{4}\, x_{5}\, x_{6}\, x_{7}\, x_{8}\, x_{9}.(λp_{1}\, p_{2}.(\bs{\prec_{3}}\, p_{1}\, R_{1}\, R_{2}\, R_{3})) \]
Donde
\begin{align*}
  R_{1} &\synteq (\bs{\prec_{3}}\, p_{2}\, x_{1}\, x_{2}\, x_{3}) \\
  R_{2} &\synteq (\bs{\prec_{3}}\,  p_{2}\, x_{4}\, x_{5}\, x_{6}) \\
  R_{3} &\synteq (\bs{\prec_{3}}\, p_{2}\, x_{7}\, x_{8}\, x_{9})
\end{align*}

\begin{algorithm}[ht]
  \caption{Operación booleana $ \odot $ dado $ x_{1} $, $ x_{2} $, ... , $ x_{9} $}
  \label{alg:op-bin-gen-2}
  \begin{algorithmic}
    \REQUIRE $ p_{1}, p_{2} \in \{ \mathrm{verdadero},\ \mathrm{falso},\ \mathrm{desconocido} \} $
    \ENSURE Valor $ x_{i} $ de la tabla de verdad
    \IF{$ p_{1} = \mathrm{verdadero} $}
    \IF{$ p_{2} = \mathrm{verdadero} $}
    \RETURN $ x_{1} $
    \ELSIF{$ p_{2} = \mathrm{falso} $}
    \RETURN $ x_{2} $
    \ELSIF{$ p_{2} = \mathrm{desconocido} $}
    \RETURN $ x_{3} $
    \ENDIF
    \ELSIF{$ p_{1} = \mathrm{falso} $}
    \IF{$ p_{2} = \mathrm{verdadero} $}
    \RETURN $ x_{4} $
    \ELSIF{$ p_{2} = \mathrm{falso} $}
    \RETURN $ x_{5} $
    \ELSIF{$ p_{2} = \mathrm{desconocido} $}
    \RETURN $ x_{6} $
    \ENDIF
    \ELSIF{$ p_{1} = \mathrm{desconocido} $}
    \IF{$ p_{2} = \mathrm{verdadero} $}
    \RETURN $ x_{7} $
    \ELSIF{$ p_{2} = \mathrm{falso} $}
    \RETURN $ x_{8} $
    \ELSIF{$ p_{2} = \mathrm{desconocido} $}
    \RETURN $ x_{9} $
    \ENDIF
    \ENDIF
  \end{algorithmic}
\end{algorithm}

\section{Aritmética}
\label{sec:aritmetica}

La aritmética es una de las ramas más antiguas de las matemáticas. Consiste en el estudio de los números y de las operaciones elementales como la suma y la multiplicación. El manejo de expresiones aritméticas es ubicuo en la vida cotidiana y es una parte fundamental de la formación básica en matemáticas.

En el cálculo $ λ $, los números naturales no son términos $ λ $, sin embargo, desde el metalenguaje se pueden manejan números naturales y expresiones aritméticas como por ejemplo en la \autoref{defn:longitud} de longitud. Al igual que el álgebra boolena, las expresiones aritméticas pueden ser codificadas como términos $ λ $.

En los lenguajes de programación los números naturales y las operaciones aritméticas son de los objetos más utilizados para expresar la mayoría de los cómputos. Virtualmente todo programa no trivial ejecutable en una computadora hace uso de números y operaciones sobre ellos. Como se menciona al inicio de la sección anterior, el concepto de número es codificado usualmente como una secuencia de bits de longitud fija y las operaciones aritméticas terminan siendo traducidas a instrucciones ejecutadas por la unidad aritmética lógica de la computadora.

En esta sección se plantea la codificación de expresiones aritméticas en el lenguaje del cálculo $ λ $ de manera similar a como se abordó en la \autoref{sec:algebra-booleana}, también se aborda la representación de la noción de iteración y algunos mecanismos que nos permiten abstraer el cómputo de las operaciones elementales.

\subsection{Numerales de Church}
\label{sec:numerales}

Los números naturales son los objetos más básicos para representar expresiones aritméticas. En este trabajo se considera que $ \mathbb{N} $ contiene el número 0, por lo que el conjunto de números naturales es
\[ \mathbb{N} = \left\{ 0,\ 1,\ 2,\ 3,\ ... \right\} \]
En la codificación del álgebra booleana se presenta la representación de valores de verdad como una decisión entre dos valores dados. En la \autoref{sec:boolean-extensiones} se extiende la representación de la decisión a tres valores y siguiendo el mismo procedimiento se puede extender a $ n $ valores. Esta representación no es útil al tratar con los números naturales ya que no se tiene un conjunto finito de valores, sin embargo, si se establece una cota superior para la cantidad de números naturales representables es posible utilizar esta codificación.

Por cuestiones de eficiencia, en las computadoras se limita la cantidad de naturales representables a valores entre 0 y $ 2^{64}-1 $, por lo tanto, es posible representar números en este rango como abstracciones de $ 2^{64} $ variables enlazadas. Utilizar esta codificación no es conveniente ya que las operaciones deberán ser definidas para cada posible combinación de naturales.

La codificación más utilizada para números naturales es la de \emph{numerales de Church}, esta codificación fue propuesta por Alonzo Church en 1941 \cite[p.~28]{Church:LambdaConversion}.

\begin{defn}[Numerales de Church]
  \label{defn:numerales-church}
  El numeral de Church, denotado $ \cn{n} $, asociado al número natural $ n $ es
  \begin{equation}
    \label{eq:numeral}
    \cn{n} \synteq (λx\, y.x^{n}\, y)
  \end{equation}
\end{defn}

Los primeros 5 numerales son:
\begin{align*}
  \cn{0} &\synteq λx\, y.x^{0}\, y \synteq λx\, y.y \\
  \cn{1} &\synteq λx\, y.x^{1}\, y \synteq λx\, y.x\, y \\
  \cn{2} &\synteq λx\, y.x^{2}\, y \synteq λx\, y.x\, (x\, y) \\
  \cn{3} &\synteq λx\, y.x^{3}\, y \synteq λx\, y.x\, (x\, (x\, y)) \\
  \cn{4} &\synteq λx\, y.x^{4}\, y \synteq λx\, y.x\, (x\, (x\, (x\, y)))
\end{align*}

Al manipular numerales de Church, se debe tener cuidado en la manera en que se reducen aplicaciones con otros términos. Con la codificación de valores de verdad es relativamente sencillo experimentar con la manera en la que $ \bs{T} $ y $ \bs{F} $ se combinan y corroborar manualmente que una combinación se reduce a otra. Sin embargo, al aplicar un numeral de Church $ \cn{n} $ a un término cualquiera $ M $, el término resultante de la contracción de dicha aplicación tendría aproximadamente una longitud de $ \| M \|\times n $, lo cual resulta inconveniente de escribir en cada paso de una reducción.

Para facilitar el desarrollo de reducciones se muestran algunas propiedades de los numerales de Church y reducciones que involucran términos de la forma $ (P^{n}\, Q) $.

Consideremos un numeral $ \cn{n} $ y términos cualesquiera $ P $ y $ Q $.
\begin{equation}
  \label{eq:numeral:P}
  \cn{n}\, P \contract{β} λx.P^{n}\, x
\end{equation} \begin{equation}
  \label{eq:numeral:PQ}
  \cn{n}\, P\, Q \contract{β} (λx.P^{n}\, x)\, Q \contract{β} P^{n}\, Q
\end{equation}

Sea $ \cn{n} $ un numeral de Church, $ P $, $ Q $ y $ R $ términos cualesquiera y $ m $ un número natural. Se aborda la reducción de las aplicaciones $ ((\cn{n}\, P\, Q)^{m}\, R) $, $ ((\cn{n}\, P)^{m}\, Q) $ y $ (\cn{n}^{m}\, P) $, las cuales corresponden a la aplicación $ (F^{m}\, X) $ donde $ F $ es el término de las ecuaciones \eqref{eq:numeral:PQ}, \eqref{eq:numeral:P} y \eqref{eq:numeral}.
\begin{align}
  \label{eq:numeral:PQm}
  (\cn{n}\, P\, Q)^{m}\, R &\reduce{β} (P^{n}\, Q)^{m}\, R &\text{Por \eqref{eq:numeral:PQ}}
\end{align}
Ya que no se hicieron suposiciones adicionales sobre $ P $ y $ Q $ no podemos asegurar que el término final de la reducción \eqref{eq:numeral:PQm} pueda ser reducido más.
\begin{align}
  \label{eq:numeral:PmQ}
  (\cn{n}\, P)^{m}\, Q \synteq &(\cn{n}\, P)^{m-1}\, (\cn{n}\, P\, Q) &\text{Por \eqref{eq:abuso:F}} \\
  \reduce{β} &(\cn{n}\, P)^{m-1}\, (P^{n}\, Q) &\text{Por \eqref{eq:numeral:PQ}} \nonumber \\
  \synteq &(\cn{n}\, P)^{m-2}\, (\cn{n}\, P\, (P^{n}\, Q)) &\text{Por \eqref{eq:abuso:F}} \nonumber \\
  \reduce{β} &(\cn{n}\, P)^{m-2}\, (P^{n}\, (P^{n}\, Q)) &\text{Por \eqref{eq:numeral:PQ}} \nonumber \\
  \synteq &(\cn{n}\, P)^{m-2}\, (P^{2\times n}\, Q) \nonumber \\
                               &\text{Repitiendo para $ m-3, ..., m-m $} \nonumber \\
  \reduce{β} &(\cn{n}\, P)^{m-m}\, (P^{m\times n}\, Q) \nonumber \\
  \synteq &P^{m\times n}\, Q &\text{Por \eqref{eq:abuso:F}} \nonumber
\end{align}

\begin{align}
  \label{eq:numeral:mP}
  \cn{n}^{m}\, P \synteq &\cn{n}^{m-1} (\cn{n}\, P) &\text{Por \eqref{eq:abuso:F}} \\
                \synteq &\cn{n}^{m-2} (\cn{n} (\cn{n}\, P)) &\text{Por \eqref{eq:abuso:F}} \nonumber \\
           \contract{β} &\cn{n}^{m-2} (λx.(\cn{n}\, P)^{n} x) &\text{Por \eqref{eq:numeral:P}} \nonumber \\
             \reduce{β} &\cn{n}^{m-2} (λx.P^{n\times n}\, x) &\text{Por \eqref{eq:numeral:PmQ}} \nonumber \\
                \synteq &\cn{n}^{m-2} (\cn{n\times n}\, P) &\text{Por \eqref{eq:numeral:P}} \nonumber \\
                        &... &\text{Repitiendo para $ m-3, ..., m-m $} \nonumber \\
             \reduce{β} &\cn{n}^{m-m} (\cn{n^{m}}\, P) \nonumber \\
                \synteq &(\cn{n^{m}}\, P) &\text{Por \eqref{eq:abuso:F}} \nonumber
\end{align}

Consideremos la reducción de una aplicación de numerales $ (\cn{n}\, \cn{m}) $. Cuando $ \cn{n} \synteq \cn{0} $ se tiene que para todo natural $ m $, $ (\cn{0}\, \cn{m}) \reduce{β} \bs{I} $ debido a que $ \cn{0} \synteq \bs{F} $ y $ (\bs{F}\, M) \reduce{β} \bs{I} $. Cuando $ \cn{n} \synteq \cn{1} $ las reducciones siguen siendo manejables, para los casos donde $ \cn{m} \synteq \cn{0}, \cn{1}, \cn{2} $ se obtienen las siguientes reducciones:
\begin{align*}
  \cn{1}\, \cn{0} &\contract{β} (λx.\cn{0}^{1}\, x) &\text{Por \eqref{eq:numeral:P}} \\
                  &\reduce{β} (λx.\cn{0^{1}}\, x) &\text{Por \eqref{eq:numeral:mP}} \\
                  &\contract{β} (λx\, y.x^{0}\, y) &\text{Por \eqref{eq:numeral:P}} \\
                  &\synteq \cn{0} \\
  \cn{1}\, \cn{1} &\contract{β} (λx.\cn{1}^{1}\, x) &\text{Por \eqref{eq:numeral:P}} \\
                  &\reduce{β} (λx.\cn{1^{1}}\, x) &\text{Por \eqref{eq:numeral:mP}} \\
                  &\contract{β} (λx\, y.x^{1}\, y) &\text{Por \eqref{eq:numeral:P}} \\
                  &\synteq \cn{1} \\
  \cn{1}\, \cn{2} &\contract{β} (λx.\cn{2}^{1}\, x) &\text{Por \eqref{eq:numeral:P}} \\
                  &\reduce{β} (λx.\cn{2^{1}}\, x) &\text{Por \eqref{eq:numeral:mP}} \\
                  &\contract{β} (λx\, y.x^{2}\, y) &\text{Por \eqref{eq:numeral:P}} \\
                  &\synteq \cn{2} \\
\end{align*}
Para cualquier numeral $ \cn{m} $:
\[ \cn{1}\, \cn{m} \contract{β} λx.\cn{m}^{1}\, x \reduce{β} λx.\cn{m^{1}}\, x \contract{β} λx\, y.x^{m}\, y \synteq \cn{m} \]

Cuando se considera $ \cn{n} \synteq \cn{2} $ las reducciones siguen los mismos pasos que en el caso anterior:
\begin{align*}
  \cn{2}\, \cn{m} &\contract{β} λx.\cn{m}^{2}\, x \reduce{β} λx.\cn{m^{2}}\, x \contract{β} λx\, y.x^{m^{2}}\, y \synteq \cn{m^{2}}
\end{align*}
Lo cual nos lleva a concluír que en el caso general, para cualesquiera numerales $ \cn{n} $ y $ \cn{m} $:
\begin{equation}
  \label{eq:numeral:nm}
  \cn{n}\, \cn{m} \contract{β} λx.\cn{m}^{n}\, x \reduce{β} λx.\cn{m^{n}}\, x \contract{β} λx\, y.x^{m^{n}}\, y \synteq \cn{m^{n}}
\end{equation}

Es curioso observar como la reducción de una aplicación sencilla entre dos numerales nos permite computar una operación aritmética relativamente compleja como la exponenciación. Este resultado pudiera parecer también preocupante, si la codificación de la operación $ n^{m} $ es tan sencillo como reducir la aplicación $ (\cn{m}\, \cn{n}) $, ¿Cómo se implementan operaciones mas simples como la suma y la multiplicación?.

En lo que resta de la sección se presentan procedimientos sistemáticos para codificar las operaciones elementales de la aritmética.

\subsection{Operaciones elementales}
\label{sec:aritmetica-elemental}

En la ecuación \eqref{eq:numeral:nm} se muestra como la aplicación de dos numerales se relaciona directamente con la operación de exponenciación. La primera aproximación a la codificación de las operaciones aritméticas seguirá un procedimiento inverso a cómo se dió con este resultado.

Las operaciones que se codificarán son la suma, la multiplicación y la exponenciación. Estas tres operaciones son binarias, es decir, a partir de dos números calculan otro. Para comenzar a codificar este tipo de operaciones consideremos una operación aritmética binaria $ \odot $ que realiza algún cálculo.

La convención para nombrar numerales será utilizada para las operaciones aritméticas, por lo tanto $ m \odot n $ se codifica como $ (\cn{\odot}\, \cn{m}\, \cn{n}) $. Ya que $ \cn{\odot} $ es una abstracción que espera ser aplicada a dos numerales, se propone que la operación codificada tenga la forma $ \cn{\odot} \synteq (λm\, n.M) $, donde $ M $ es un término que al reducir la aplicación $ (\cn{\odot}\, \cn{a}\, \cn{b}) $ es equivalente a $ (λx\, y.x^{a \odot b}\, y) $.

En el caso de la codificación de la exponenciación, denotada $ \cn{\uparrow} $, se tiene que $ (\cn{\uparrow}\, \cn{m}\, \cn{n}) $ debe reducirse a
\[ λx\, y.x^{m^{n}}\, y \]
Se puede derivar el término $ \cn{\uparrow} $ observando que
\begin{align*}
  λx\, y.x^{m^{n}}\, y &\synteq \cn{m^{n}} &\text{Por \eqref{eq:numeral}} \\
                       &\convertible{β} \cn{n}\, \cn{m} &\text{Por \eqref{eq:numeral:nm}} \\
                       &\convertible{β} λx\, y.\cn{n}\, \cn{m}\, x\, y
\end{align*}
Por lo tanto, la codificación de la exponenciación es
\begin{equation}
  \label{eq:numeral:exp1}
  \cn{\uparrow} \synteq λm\, n.λx\, y.n\, m\, x\, y
\end{equation}

En el caso de la codificación de la multiplicación, denotada $ \cn{\times} $, se tiene que $ (\cn{\times}\, \cn{m}\, \cn{n}) $ debe reducirse a
\[ λx\, y.x^{n\times m}\, y \]
Para derivar el término $ \cn{\times} $ se observa que
\begin{align*}
  λx\, y.x^{n\times m}\, y &\convertible{β} λx\, y.(\cn{m}\, x)^{n}\, y &\text{Por \eqref{eq:numeral:PmQ}} \\
                           &\convertible{β} λx\, y.\cn{n}\, (\cn{m}\, x)\, y &\text{Por \eqref{eq:numeral:PQ}}
\end{align*}
Por lo tanto, la codificación de la multiplicación es
\begin{equation}
  \label{eq:numeral:mul1}
  \cn{\times} \synteq λm\, n.λx\, y.n(m\, x)y
\end{equation}

Finalmente, con la operación de adición, denotada $ \cn{+} $, se tiene que $ (\cn{+}\, \cn{m}\, \cn{n}) $ debe reducirse a
\[ λx\, y.x^{n+m}\, y \]
Para derivar el término $ \cn{+} $ se observa que
\begin{align*}
  λx\, y.x^{n+m}\, y &\synteq λx\, y.x^{n}\, (x^{m}\, y) &\text{Por \eqref{eq:abuso:F}} \\
                     &\convertible{β} λx\, y.x^{n}\, (\cn{m}\, x\, y) &\text{Por \eqref{eq:numeral:PQ}} \\
                     &\convertible{β} λx\, y.\cn{n}\, x\, (\cn{m}\, x\, y) &\text{Por \eqref{eq:numeral:PQ}}
\end{align*}
Por lo tanto, la codificación de la adición es
\begin{equation}
  \label{eq:numeral:sum1}
  \cn{+} \synteq λm\, n.λx\, y.n\, x\, (m\, x\, y)
\end{equation}
Las codificaciones \eqref{eq:numeral:exp1}, \eqref{eq:numeral:mul1} y \eqref{eq:numeral:sum1} fueron construídas a partir de las reducciones mostradas en \eqref{eq:numeral:PmQ}, \eqref{eq:numeral:mP} y \eqref{eq:numeral:nm}, las cuales a su vez fueron obtenidas a partir del abuso de notación definido en \eqref{eq:abuso:F} el cual refleja la estructura de los numerales de Church, por lo tanto, las codificaciones mostradas se basan únicamente en la estructura de los numerales. Sin embargo, las operaciones de adición, multiplicación y exponenciación no son únicamente cálculos independientes que permiten expresar expresiones aritméticas. Estas tres operaciones se encuentran conceptualmente relacionadas.

\begin{figure}[!htbp]
  \begin{align*}
    \cn{+} & &\synteq& & \mathcolor{gray}{λm\, n.λx\, y.}\mathcolor{red}{n}\, x\, (\mathcolor{blue}{m}\, x\, y) & &\synteq& & \mathcolor{gray}{(λm.(λn.(λx.(λy.}((n\, x)\, \mathcolor{magenta}{((m\, x)\, y)})\mathcolor{gray}{))))} \\
    \cn{\times} & &\synteq& & \mathcolor{gray}{λm\, n.λx\, y.}\mathcolor{red}{n}\, (\mathcolor{blue}{m}\, x)y & &\synteq& & \mathcolor{gray}{(λm.(λn.(λx.(λy.}((n\, \mathcolor{magenta}{(m\, x)})\, y)\mathcolor{gray}{))))} \\
    \cn{\uparrow} & &\synteq& &\mathcolor{gray}{λm\, n.λx\, y.}\mathcolor{red}{n}\, \mathcolor{blue}{m}\, x\, y & &\synteq& & \mathcolor{gray}{(λm.(λn.(λx.(λy.}(((n\, \mathcolor{magenta}{m})\, x)\, y)\mathcolor{gray}{))))}
  \end{align*}
  \caption{Codificaciones de adición, multiplicación y exponenciación}
  \label{fig:numeral:cod1comp}
\end{figure}

En la \autoref{fig:numeral:cod1comp} se puede apreciar la diferencia estructural entre las codificaciones definidas, las similitudes se encuentran coloreadas en gris.

La segunda columna muestra las tres codificaciones escritas de manera compacta, se observa que en los tres casos, la aparición de $ n $ se encuentra antes que la aparición de $ m $. Debido a que los numerales de Church son abstracciones, al reducir la aplicación de una operación a dos numerales $ \cn{m} $ y $ \cn{n} $, la estructura del resultado en su forma normal se basará principalmente en la estructura de $ \cn{n} $. Esto no es muy relevante en el caso de $ \cn{+} $ y $ \cn{\times} $ ya que las operaciones son conmutativas, por lo tanto, no es importante si se intercambian las apariciones de $ n $ y $ m $, sin embargo, la exponenciación no es una operación conmutativa, el numeral base y el numeral exponente juegan papeles diferentes en la operación.

La tercera columna muestra las tres codificaciones escritas sin abuso de notación, se observa que la aparición de $ m $ se agrupa con las variables $ x $ y $ y $ de manera similar a las ecuaciones \eqref{eq:numeral}, \eqref{eq:numeral:P} y \eqref{eq:numeral:PQ}, las cuales fueron utilizadas en las ecuaciones \eqref{eq:numeral:PmQ}, \eqref{eq:numeral:mP} y \eqref{eq:numeral:nm}.

La figura nos permiten razonar sobre la manera en como se $ β $-reduce la aplicación de las operaciones, sin embargo, las similitudes en la estructura de las codificaciones no refleja las similitudes de las operaciones, por lo que es difícil razonar sobre las operaciones a partir de su definición.

En la \autoref{sec:algebra-booleana}, las codificaciones desarrolladas se basaron en una relación fundamental entre los valores de verdad y una desición, esto permitió construir abstracciones componibles que facilitaron codificar y razonar sobre las expresiones booleanas, a tal grado que se estableció una correspondencia directa entre las expreciones condicionales de los lenguajes de programación y las operaciones booleanas.

Para lograr este mismo efecto con la codificación de la aritmética, se deben hacer observaciones más fundamentales sobre la estructura de los numerales de Church y las nociones de las operaciones aritméticas.

Los números naturales nacieron a la par de la necesidad humana de \emph{contar}. De manera similar a la analogía presentada al inicio de la \autoref{sec:valores-de-verdad} se plantea la siguiente situación hipotética:

Una persona omnisciente y muda llamada $ P $ puede decirme la cantidad de objetos en el mundo si le planteo una pregunta con una respuesta contable y le doy un martillo y un clavo; la cantidad de objetos va a corresponder a la cantidad de veces que $ P $ golpea el clavo con el martillo. En este planteamiento irreal e hipotético, no es necesario conocer la estructura del número, sólo es necesario tener a alguien que pueda contar y proveer dos objetos sabiendo que la persona va a realizar algo con el primero sobre el segundo (en este caso, golpear con el martillo al clavo). El procedimiento que realiza esta persona puede representar valores numéricos si nunca podemos conocer a los números naturales.

Detrás del concepto de contar, está el concepto de \emph{repetición}, la estructura de los numerales de Church se puede interpretar como la analogía entre repetición y número.

Sea $ P $ un término $ λ $ el cual puede ser aplicado a una pregunta $ Q $, al $ β $-reducir $ (P\, Q) $ se obtiene una repetición $ R $ la cual al ser aplicada a una acción $ A $ y un objeto $ O $ se $ β $-reduce a realizar la acción $ A $ sobre $ O $ y repetir el procedimiento con el resultado hasta haber realizado cierta cantidad de acciones:

\[ P\, Q \reduce{β} R, \]
\[ R\, A\, O \reduce{β} \underbrace{A(A(\ ...\ (A(A\, O))\ ...\ ))}_\text{$ n $ veces} \]

Para fines prácticos no es necesario conocer la estructura de $ P $ ni de $ Q $, lo importante es que $ A $ se realice cierta cantidad de veces sobre $ O $. Por lo tanto $ R $ es un término $ λ $ de la forma
\[ λx\, y.x\, (x\, (\ ...\ (x\, (x\, y))\ ...\ )) \]
La cual corresponde a la estructura de los numerales de Church.

Teniendo una justificación conceptual e informal para considerar a los números como repeticiones podemos estudiar las operaciones aritméticas a partir de esta perspectiva.

Al inicio de esta sección se construyeron las codificaciones de las operaciones aritméticas en un orden peculiar. Primero la exponenciación, después la multiplicación y al final la adición. Esto es bastante raro debido a que la exponenciación suele ser considerada una operación más compleja que la multiplicación y a su vez esta más compleja que la adición, la estructura de las codificaciones parece aumentar en complejidad entre menos complejas son las operaciones que describen.

La percepción de complejidad de operaciones aritméticas se remonta a la manera en cómo se enseña la aritmética en la educación básica. Después de aprender a contar, se aprende a sumar y después a multiplicar. A pesar de ser en un inicio un proceso de memorización, el acto de sumar y multiplicar números pequeños termina siendo un acto trivial, empleando algoritmos y heurísticas de estimación cuando los números son grandes. En el caso de la exponenciación, los computólogos suelen adquirir esta misma capacidad cuando se trata de operaciones de la forma $ 2^{n} $ debido a la repetida utilización de números en base 2. Sin embargo, esta percepción tiene también una justificación algorítmica.

La operación de multiplicación puede ser definida en función de la operación de adición. Sean $ m $ y $ n $ dos números naturales, la operación $ m \times n $ es equivalente a sumar $ m $ consigo mismo $ n $ veces.
\begin{equation}
  \label{eq:numeral:muldef}
  m \times n = \underbrace{m + m + ... + m}_\text{$ n $ veces} = \sum_{i=1}^{n} m
\end{equation}
De manera análoga, la operación de exponenciación puede ser definida en función de la operación de multiplicación. Sean $ m $ y $ n $ dos números naturales, la operación $ m^{n} $ es equivalente a multiplicar $ m $ consigo mismo $ n $ veces.
\begin{equation}
  \label{eq:numeral:expdef}
  m^{n} = \underbrace{m \times m \times ... \times m}_\text{$ n $ veces} = \prod_{i=1}^{n} m
\end{equation}
De esta manera, una operación compleja como la exponenciación se define en términos de una operación más fundamental como la multiplicación. Esta observación trae a colación la pregunta, ¿cuál es la operación aritmética más fundamental?.

La respuesta a esta pregunta no es fácil de encontrar, se pudiera pensar que la adición es la operación más fundamental, sin embargo, la adición puede ser definida en función de la operación unaria sucesor y esta a su vez es un caso particular de la adición. Sea $ +_{1} $ el operador unario sucesor
\[ m + n = \underbrace{+_{1} +_{1} ... {} +_{1}}_\text{$ n $ veces} m = \underbrace{1 + 1 + ... + 1}_\text{$ n $ veces}+m \]
En la segunda aproximación de las codificaciones, se considera que el operador de sucesor es más fundamental que la adición debido a que es fácil codificar la sucesión sin basarse en resultados previos.

La definición de la operación de sucesor consiste en ``añadir'' una variable $ x $ a un número, ya que
\[ \cn{n} \synteq λx\, y.\underbrace{x\, (x\, (\ ...\ (x\, y)))}_\text{$ n $ apariciones de $ x $} \]
solo se necesita obtener el cuerpo del numeral con la aplicación $ (\cn{n}\, x\, y) $ y aplicar $ x $ al resultado de la reducción. La codificación del operador $ \cn{+}_{1} $ es
\begin{equation}
  \label{eq:numeral:suc2}
  \cn{+}_{1} \synteq λn.λx\, y.x\, (n\, x\, y)
\end{equation}
Para demostrar que esta definición es correcta, consideremos la reducción de la aplicación de $ \cn{+}_{1} $ en un numeral cualquiera $ \cn{n} $:
\begin{align}
  \label{eq:numeral:suc2dem}
  \cn{+}_{1}\, \cn{n} \synteq &(λn.λx\, y.x\, (n\, x\, y))\, \cn{n} &\text{Por \eqref{eq:numeral:suc2}} \\
                \contract{β} &λx\, y.x\, (\cn{n}\, x\, y) \nonumber \\
                  \reduce{β} &λx\, y.x\, (x^{n}\, y) &\text{Por \eqref{eq:numeral:PQ}} \nonumber \\
                     \synteq &λx\, y.x^{n+1}\, y &\text{Por \eqref{eq:abuso:F}} \nonumber \\
                     \synteq &\cn{n+1} \nonumber
\end{align}
Ahora se debe plantear una manera de aplicar el concepto de repetición de sucesores para obtener la adición. La operación $ \cn{+} $ deberá tomar dos numerales $ \cn{m} $ y $ \cn{n} $ y repetir $ \cn{n} $ veces la operación de sucesor sobre $ \cn{m} $. Ya que la aplicación de $ \cn{+}_{1} $ a un numeral, resulta en un numeral basta con aplicar $ \cn{n} $ al operador $ \cn{+}_{1} $ y al numeral $ \cn{m} $. Por ejemplo
\begin{align*}
  (\cn{3}\, \cn{+}_{1}\, \cn{4}) \reduce{β} &\cn{+}_{1}\, (\cn{+}_{1}\, (\cn{+}_{1}\, \cn{4})) &\text{Por \eqref{eq:numeral:PQ}} \\
                                 \reduce{β} &\cn{+}_{1}\, (\cn{+}_{1}\, \cn{5}) &\text{Por \eqref{eq:numeral:suc2dem}} \\
                                 \reduce{β} &\cn{+}_{1}\, \cn{6} &\text{Por \eqref{eq:numeral:suc2dem}} \\
                                 \reduce{β} &\cn{7} &\text{Por \eqref{eq:numeral:suc2dem}}
\end{align*}
En general, para cualesquiera $ \cn{m} $ y $ \cn{n} $, la aplicación $ (\cn{n}\, \cn{+}_{1}\, \cn{m}) $ se reduce a:
\begin{align}
  \label{eq:numeral:sum2dem}
  \cn{n}\, \cn{+}_{1}\, \cn{m} \reduce{β} &\cn{+}_{1}^{n}\, \cn{m} &\text{Por \eqref{eq:numeral:PQ}} \\
                                 \synteq &\cn{+}_{1}^{n-1}\, (\cn{+}_{1}\, \cn{m}) &\text{Por \eqref{eq:abuso:F}} \nonumber \\
                              \reduce{β} &\cn{+}_{1}^{n-1}\, \cn{m+1} &\text{Por \eqref{eq:numeral:suc2dem}} \nonumber \\
                                      ...& \nonumber \\
                              \reduce{β} &\cn{+}_{1}^{n-n}\, \cn{m+n} \nonumber \\
                                 \synteq &\cn{m+n} &\text{Por \eqref{eq:abuso:F}} \nonumber
\end{align}
La codificación del operador $ \cn{+} $ es
\begin{equation}
  \label{eq:numeral:sum2}
  \cn{+} \synteq λm\, n.n\, \cn{+}_{1}\, m
\end{equation}
Para codificar la operación de multiplicación y exponenciación se puede seguir el mismo patrón: un numeral $ \cn{n} $ determina una cantidad de repeticiones, es aplicado a una operación unaria que será aplicada $ n $ veces a un término. Hay dos detalles importantes que considerar, primero, cómo convertir una codificación de una operación binaria a unaria y qué valor aplicar al final.

En el caso de la codificación de la multiplicación se debe convertir a $ \cn{+} $ en una operación unaria, por la definición de multiplicación \eqref{eq:numeral:muldef} se tiene que
\[ m + m + ... + m = m + m + ... + m + 0 = (m + (m + ... + (m + 0) ...)) \]
Esto es, se repite la aplicación de una abstracción que toma un numeral y computa la suma de el numeral y $ m $, cierta cantidad de veces, comenzando con el numeral $ \cn{0} $. Para construir la versión unaria de $ \cn{+} $ se puede plantear la abstracción $ λn.(\cn{+}\, n\, \cn{m}) $, sin embargo hay una manera más conveniente de escribir esta abstracción. Si consideramos la definición \eqref{eq:numeral:sum2} y la aplicamos únicamente a un numeral, se reduce a
\[ \cn{+}\, \cn{m} \synteq (λm\, n.n\, \cn{+}_{1}\, m)\, \cn{m} \contract{β} λn.n\, \cn{+}_{1}\, \cn{m} \]
El cual al ser aplicado a algun numeral $ \cn{n} $ será reducido a un término $ β $-convertible a $ (\cn{+}\, \cn{m}\, \cn{n}) $. Por lo tanto, la aplicación $ (\cn{n}\, (\cn{+}\, \cn{m})\, \cn{0}) $ computa la multiplicación de $ \cn{m} $ y $ \cn{n} $. Por ejemplo
\begin{align*}
  \cn{3}\, (\cn{+}\, \cn{4}) \cn{0} \reduce{β} &(\cn{+}\, \cn{4})^{3}\, \cn{0} &\text{Por \eqref{eq:numeral:PQ}} \\
                                     \synteq &(\cn{+}\, \cn{4})^{2}\, (\cn{+}\, \cn{4}\, \cn{0}) &\text{Por \eqref{eq:abuso:F}} \\
                                  \reduce{β} &(\cn{+}\, \cn{4})^{2}\, \cn{4} &\text{Por \eqref{eq:numeral:sum2dem}} \\
                                     \synteq &(\cn{+}\, \cn{4})\, (\cn{+}\, \cn{4}\, \cn{4}) &\text{Por \eqref{eq:abuso:F}} \\
                                  \reduce{β} &(\cn{+}\, \cn{4})\, \cn{8} &\text{Por \eqref{eq:numeral:sum2dem}} \\
                                     \synteq &(\cn{+}\, \cn{4})^{0}\, (\cn{+}\, \cn{4}\, \cn{8}) &\text{Por \eqref{eq:abuso:F}} \\
                                  \reduce{β} &(\cn{+}\, \cn{4})^{0}\, \cn{12} &\text{Por \eqref{eq:numeral:sum2dem}} \\
                                     \synteq &\cn{12} &\text{Por \eqref{eq:abuso:F}}
\end{align*}
En general, para cualesquiera $ \cn{m} $ y $ \cn{n} $, la aplicación $ (\cn{n}\, (\cn{+}\, \cn{m})\, \cn{0}) $ se reduce a:
\begin{align}
  \label{eq:numeral:mul2dem}
  \cn{n}\, (\cn{+}\, \cn{m}) \cn{0} \reduce{β}& (\cn{+}\, \cn{m})^{n}\, \cn{0} &\text{Por \eqref{eq:numeral:PQ}} \\
                                       \synteq& (\cn{+}\, \cn{m})^{n-1}\, (\cn{+}\, \cn{m}\, \cn{0}) &\text{Por \eqref{eq:abuso:F}} \nonumber \\
                                    \reduce{β}& (\cn{+}\, \cn{m})^{n-1}\, \cn{m+0} &\text{Por \eqref{eq:numeral:sum2dem}} \nonumber \\
                                       \synteq& (\cn{+}\, \cn{m})^{n-2}\, (\cn{+}\, \cn{m}\, \cn{m+0}) &\text{Por \eqref{eq:abuso:F}} \nonumber \\
                                    \reduce{β}& (\cn{+}\, \cn{m})^{n-2}\, \cn{m\times 2 + 0} &\text{Por \eqref{eq:numeral:sum2dem}} \nonumber \\
                                           ...& \nonumber \\
                                    \reduce{β}& (\cn{+}\, \cn{m})^{n-n}\, \cn{m\times n + 0} \nonumber \\
                                       \synteq& \cn{m\times n} &\text{Por \eqref{eq:abuso:F}} \nonumber
\end{align}
La codificación del operador $ \cn{\times} $ es
\begin{equation}
  \label{eq:numeral:mul2}
  \cn{\times} \synteq λm\, n.n\, (\cn{+}\, m)\, \cn{0}
\end{equation}

De manera análoga, se utiliza la definición de exponenciación \eqref{eq:numeral:expdef} para definir su codificación en función de $ \cn{\times} $. Sean $ \cn{m} $ y $ \cn{n} $ dos numerales cualesquiera, la aplicación $ (\cn{\uparrow}\, \cn{m}\, \cn{n}) $ debe repetir la multiplicación de la base $ \cn{m} $ una cantidad de veces determinada por el exponente $ \cn{n} $. La codificación es muy similar a la de multiplicación, sólo que utilizando como término final el numeral $ \cn{1} $ ya que $ \prod_{i=1}^{n} m = 1 \times \prod_{i=1}^{n} m $. Para corroborar que la aplicación $ (\cn{n} (\cn{\times}\, \cn{m})\, \cn{1}) $ computa la exponenciación de $ \cn{m} $ a la $ \cn{n} $ se desarrolla el siguiente ejemplo
\begin{align*}
  \cn{3}\, (\cn{\times}\, \cn{4})\, \cn{1} \reduce{β} &(\cn{\times}\, \cn{4})^{3}\, \cn{1} &\text{Por \eqref{eq:numeral:PQ}} \\
                                          \synteq &(\cn{\times}\, \cn{4})^{2}\, (\cn{\times}\, \cn{4}\, \cn{1}) &\text{Por \eqref{eq:abuso:F}} \\
                                       \reduce{β} &(\cn{\times}\, \cn{4})^{2}\, \cn{4} &\text{Por \eqref{eq:numeral:mul2dem}} \\
                                          \synteq &(\cn{\times}\, \cn{4})^{1}\, (\cn{\times}\, \cn{4}\, \cn{4}) &\text{Por \eqref{eq:abuso:F}} \\
                                       \reduce{β} &(\cn{\times}\, \cn{4})^{1}\, \cn{16} &\text{Por \eqref{eq:numeral:mul2dem}} \\
                                          \synteq &(\cn{\times}\, \cn{4})^{0}\, (\cn{\times}\, \cn{4}\, \cn{16}) &\text{Por \eqref{eq:abuso:F}} \\
                                       \reduce{β} &(\cn{\times}\, \cn{4})^{0}\, \cn{64} &\text{Por \eqref{eq:numeral:mul2dem}} \\
                                          \synteq &\cn{64}
\end{align*}

En general, para cualesquiera $ \cn{m} $ y $ \cn{n} $, la aplicación $ (\cn{n} (\cn{\times}\, \cn{m}) \cn{1}) $ se reduce a:
\begin{align}
  \label{eq:numeral:exp2dem}
  \cn{n}\, (\cn{\times}\, \cn{m})\, \cn{1} \reduce{β} &(\cn{\times}\, \cn{m})^{n}\, \cn{1} &\text{Por \eqref{eq:numeral:PQ}} \\
                                          \synteq &(\cn{\times}\, \cn{m})^{n-1}\, (\cn{\times}\, \cn{m}\, \cn{1}) &\text{Por \eqref{eq:abuso:F}} \nonumber \\
                                       \reduce{β} &(\cn{\times}\, \cn{m})^{n-1}\, \cn{m\times 1} &\text{Por \eqref{eq:numeral:mul2dem}} \nonumber \\
                                          \synteq &(\cn{\times}\, \cn{m})^{n-2}\, (\cn{\times}\, \cn{m}\, \cn{m\times 1}) &\text{Por \eqref{eq:abuso:F}} \nonumber \\
                                       \reduce{β} &(\cn{\times}\, \cn{m})^{n-2}\, \cn{m^{2}\times 1} &\text{Por \eqref{eq:numeral:mul2dem}} \nonumber \\
                                              ... &\nonumber \\
                                       \reduce{β} &(\cn{\times}\, \cn{m})^{n-n}\, \cn{m^{n}\times 1} \nonumber \\
                                          \synteq &\cn{m^{n}} \nonumber
\end{align}

La codificación del operador $ \cn{\uparrow} $ es
\begin{equation}
  \label{eq:numeral:exp2}
  \cn{\uparrow} \synteq λm\, n.n\, (\cn{\times}\, m)\, \cn{1}
\end{equation}

Comparando esta segunda aproximación de las codicicaciones de $ \cn{+} $, $ \cn{\times} $ y $ \cn{\uparrow} $ se pueden observar relaciones tanto en estructura como en significado.

En la \autoref{fig:numeral:cod2comp} se puede apreciar la diferencia estrucural entre las codificaciones definidas, las similitudes menos importantes se encuentran coloreadas en gris.

\begin{figure}[!htbp]
  \begin{align*}
    \cn{+} &&\synteq&& \mathcolor{gray}{λm\, n.}\mathcolor{red}{n}\, \cn{+}_{1}\, \mathcolor{blue}{m}  &&\synteq&& \mathcolor{gray}{(λm.(λn.}((n\, \mathcolor{magenta}{\cn{+}_{1}})\, m)\mathcolor{gray}{))} \\
    \cn{\times} &&\synteq&& \mathcolor{gray}{λm\, n.}\mathcolor{red}{n}\, (\cn{+}\, m)\, \mathcolor{blue}{\cn{0}}  &&\synteq&& \mathcolor{gray}{(λm.(λn.}((n\, \mathcolor{magenta}{(\cn{+}\, m)})\, \cn{0})\mathcolor{gray}{))} \\
    \cn{\uparrow} &&\synteq&& \mathcolor{gray}{λm\, n.}\mathcolor{red}{n}\, (\cn{\times}\, m)\, \mathcolor{blue}{\cn{1}}  &&\synteq&& \mathcolor{gray}{(λm.(λn.}((n\, \mathcolor{magenta}{(\cn{\times}\, m)})\, \cn{1})\mathcolor{gray}{))}
  \end{align*}
  \caption{Codificaciones de adición, multiplicación y exponenciación}
  \label{fig:numeral:cod2comp}
\end{figure}

La segunda columna muestra las tres codificaciones escritas de manera compacta, se observa que en los tres casos el átomo $ n $ corresponde al operando derecho de la operación y es el que determina la cantidad de veces que se aplicará un procedimiento. Coloreados con azúl se encuentran los valores iniciales a los que se aplica el procedimiento, estos corresponden al caso trivial de la operación, es decir, si $ n $ es cero, entonces el resultado de la suma es $ m $, el de la multiplicación es $ 0 $ y el de la exponenciación es $ 1 $.

En la tercera columna se encuentran las codificaciones escritas sin abuso de notación, coloreado en magenta están los términos a los que $ n $ es aplicado primero, esto es, los términos que serán aplicados una y otra vez. Estos términos se encuentran en función de la operación anterior (en orden de menor a mayor complejidad). Al ver las definiciones se puede saber que la expoenciación es repetición de multiplicaciones con caso base $ 1 $, la multiplicación es repetición de adiciones con caso base $ 0 $ y la adición es repetición de sucesiones con caso base $ m $.

Teniendo codificaciones definidas de manera compacta y elegante, solo queda preguntarnos cómo obtener el resto de las operaciones aritméticas elementales, es decir, la sustracción, la división y para completar las inversas, el logaritmo y la raíz.

Estas operaciones inversas pueden ser vistas de manera similar a la adición, multiplicación y exponenciación, solo que en lugar de añadir aplicaciones, eliminar aplicaciones. Esto se puede lograr con la operación \emph{predecesor}, definida como una operación unaria cerrada en los naturales como
\begin{align*}
  -_{1} 0 &= 0 \\
  -_{1} n &= n-1
\end{align*}
La estructura de los numerales de Church favorece los mecanismos que añaden aplicaciones. En la codificación del sucesor fue relativamente sencillo ``revincular'' las variables ligadas en $ \cn{n} $ de tal manera que sólo se necesitaba aplicar $ x $ a $ (x^{n}\, y) $ para obtener $ (x^{n+1}\, y) $. Sin embargo, para codificar el predecesor es necesario ``eliminar'' una $ x $ de la aplicación y no hay manera sencilla de lograr esto.

Henk Barendreght, en el artículo titulado ``The Impact of Lambda Calculus in Logic and Computer Science'' \cite{Barendregt:Impact}, menciona que la codificación del predecesor en el cálculo $ λ $ fue un problema abierto. Alonzo Church pudo codificar la adición, la multiplicación y la exponenciación, sin embargo, la función predecesor resultaba ser extremadamente difícil de encontrar con sus numerales.

Stephen Kleene, estudiante de Alonzo Church, encontró la solución de la misteriosa codificación del predecesor. Sin embargo se tuvo que auxiliar de una representación alternativa para los números naturales. De acuerdo a \cite{Barendregt:Impact}, Kleene hizo uso de una codificación de pares de números $ \langle n-1,n \rangle $. Se inicia con $ \langle 0,0 \rangle $ y el sucesor de $ \langle a,b \rangle $ es $ \langle b,b+1 \rangle $. Cuando Kleene le llevó la propuesta a Church, este ya se había convencido que el cálculo $ λ $ era un sistema demasiado débil para representar el predecesor; es entonces que Church, habiendo aprendido que el predecesor era definible en el cálculo $ λ $, se convenció de que todas las funciones que eran intuitivamente computables, eran definibles en el cálculo $ λ $.

Para definir la codificación del predecesor, no se hará uso de la técnica de Kleene, pero si se introducirá otra notación para los números naturales.

Lo que hace que la estructura de los numerales de Church no sea adecuada es que no se tiene una manera sencilla de remover aplicaciones. Sin embargo, podemos considerar una modificación a los numerales de Church, de tal manera que el mecanismo para quitar y añadir aplicaciones sea sencillo.

Sea $ \cn{n} $ un numeral de Church, su estructura $ (λx\, y.x^{n}\, y) $ se modifica para que una de las apariciones de $ x $ se enlace a una variable diferente, por ejemplo $ z $, de tal manera que la cantidad de $ x $ sumada a la cantidad de $ z $ sea el número representado. Consideremos que el numeral modificado $ \cn{n}' $ tiene la última $ x $ de $ \cn{n} $ como $ z $, su definición sería:
\[ \cn{n}^{\prime} \synteq λx\, y\, z.x^{n-1}\, (z\, y) \]
En esta nueva codificación, los primeros cinco números son codificados como
\begin{align*}
  \cn{0}^{\prime} &\synteq λx\, y\, z.y \\
  \cn{1}^{\prime} &\synteq λx\, y\, z.z\, y \\
  \cn{2}^{\prime} &\synteq λx\, y\, z.x\, (z\, y) \\
  \cn{3}^{\prime} &\synteq λx\, y\, z.x\, (x\, (z\, y)) \\
  \cn{4}^{\prime} &\synteq λx\, y\, z.x\, (x\, (x\, (z\, y)))
\end{align*}
La clave de utilizar esta representación modificada está en observar que es fácil pasar de $ \cn{n}^{\prime} $ a $ \cn{n-1} $. Sea $ \cn{n}^{\prime} $ un numeral en la codificación modificada, la reducción de la aplicación $ (\cn{n}^{\prime}\, x\, y\, \bs{I}) $ resulta en $ (x^{n-1}\, y) $.

\begin{align*}
  \cn{n}^{\prime}\, x\, y\, \bs{I} \synteq &(λx\, y\, z.x^{n-1}\, (z\, y))\, x\, y\, \bs{I} \\
                              \reduce{β} &x^{n-1}\, (\bs{I}\, y) \\
                            \contract{β} &x^{n-1}\, y
\end{align*}

De tal manera que la definición del predecesor $ \cn{-}_{1} $ para la codificación de Church puede ser escrita
\[ \cn{-}_{1} \synteq λn.λx\, y.\mc{T}[n\mapsto n^{\prime}]\, x\, y\, \bs{I} \]
Donde $ \mc{T}[n\mapsto n^{\prime}] $ es una transformación que a partir de $ n $ obtiene el mísmo número pero con la codificación modificada. Con la cual es sencillo encontrar $ n-1 $.

Para construir el término $ \mc{T}[n\mapsto n^{\prime}] $ se debe encontrar una manera de contar desde $ 0 $ hasta $ n $ en la codificación modificada. Esto se puede lograr utilizando la interpretación de los numerales de Church como operadores de repetición. Si se construye una codificación del sucesor $ \cn{+}_{1}^{\prime} $ para los numerales modificados, entonces $ \mc{T}[n\mapsto n^{\prime}] $ puede ser definida como $ n $ aplicaciones de $ \cn{+}^{\prime} $ con el caso base $ \cn{0}^{\prime} $, es decir
\[ \mc{T}[n\mapsto n^{\prime}] \synteq n\, \cn{+}_{1}^{\prime}\, \cn{0}^{\prime} \]
El problema de codificar el predecesor se reduce ahora a la construcción del sucesor de un número con la codificación modificada. Esta construcción resulta ser casi tan sencilla como la codificación de $ \cn{+}_{1} $. Primero se analiza cómo cambia la estructura de la codificación de $ \cn{n}^{\prime} $ a $ \cn{n+1}^{\prime} $:
\begin{align*}
  \cn{+}_{1}^{\prime}\, \cn{0}^{\prime} && \synteq && \cn{+}_{1}^{\prime}\, (λx\, y\, z.y) && \reduce{β} && λx\, y\, z.z\, y \\
  \cn{+}_{1}^{\prime}\, \cn{1}^{\prime} && \synteq && \cn{+}_{1}^{\prime}\, (λx\, y\, z.z\, y) && \reduce{β} && λx\, y\, z.x(z\, y)\\
  \cn{+}_{1}^{\prime}\, \cn{2}^{\prime} && \synteq && \cn{+}_{1}^{\prime}\, (λx\, y\, z.x\, (z\, y)) && \reduce{β} && λx\, y\, z.x(x(z\, y))\\
  \cn{+}_{1}^{\prime}\, \cn{3}^{\prime} && \synteq && \cn{+}_{1}^{\prime}\, (λx\, y\, z.x\, (x\, (z\, y))) && \reduce{β} && λx\, y\, z.x\, (x\, (x\, (z\, y)))
\end{align*}

Cuando se computa el sucesor de $ \cn{0}^{\prime} $, la única variable enlazada es $ y $ y el resultado es $ z\, y $, por lo tanto, la $ y $ será sustituida por $ (z\, y) $ en el sucesor. Cuando se computa el sucesor de $ \cn{1}^{\prime} $, se tienen variables enlazadas $ z $ y $ y $, si $ y $ es sustituido por $ (z\, y) $, la $ z $ deberá ser sustituida por $ x $ en el sucesor. Cuando se computa el sucesor de $ \cn{2}^{\prime} $, se tienen variables enlazadas $ x $, $ z $ y $ y $, si se suponen las sustituciones de los otros dos casos, la $ x $ deberá ser sustituida por $ x $ en el sucesor. Para corroborar que estas sustituciones son correctas para un caso concreto, se considera la aplicación $ (\cn{3}^{\prime}\, x\, (z\, y)\, x) $:
\begin{align*}
  \cn{3}^{\prime}\, x\, (z\, y)\, x &\reduce{β} x^{2}\, (x\, (z\, y)) \\
                                    &\synteq x^{3}\, (z\, y)
\end{align*}
Y en general, aplicar estos términos a un numeral modificado $ \cn{n}^{\prime} $ se reduce a
\begin{align*}
  \cn{n}^{\prime}\, x\, (z\, y) x &\reduce{β} x^{n-1}\, (x\, (z\, y)) \\
                                &\synteq x^{n}\, (z\, y)
\end{align*}
Término que corresponde al cuerpo del numeral $ \cn{4}^{\prime} $. Por lo tanto, la codificación de la operación $ \cn{+}_{1}^{\prime} $ es:
\[ \cn{+}_{1}^{\prime} \synteq λn^{\prime}.λx\, y\, z.n^{\prime}\, x\, (z\, y)\, x \]
Con estas piezas, la codificación de la operación predecesor se define como
\begin{equation}
  \label{eq:numeral:pred2}
  \cn{-}_{1} \synteq λn.λx\, y.(n\, \cn{+}_{1}^{\prime}\, \cn{0}^{\prime})\, x\, y\, \bs{I}
\end{equation}
Para corroborar que la codificación computa el resultado deseado, consideremos los casos $ \cn{n} \synteq \cn{0} $ y $ \cn{n} \synteq \cn{k} $ en la reducción de la aplicación $ (\cn{-}_{1}\, \cn{n}) $:
\begin{align*}
  \cn{-}_{1}\, \cn{0} \contract{β} &λx\, y.(\cn{0}\, \cn{+}_{1}^{\prime}\, \cn{0}^{\prime})\, x\, y\, \bs{I} \\
                        \reduce{β} &λx\, y.(\bs{I} \cn{0}^{\prime})\, x\, y\, \bs{I} \\
                      \contract{β} &λx\, y.\cn{0}^{\prime}\, x\, y\, \bs{I} \\
                           \synteq &λx\, y.(λx\, y\, z.y)\, x\, y\, \bs{I} \\
                        \reduce{β} &λx\, y.y \\
                           \synteq &\cn{0} \\
  \cn{-}_{1}\, \cn{k} \contract{β} &λx\, y.(\cn{k}\, \cn{+}_{1}^{\prime}\, \cn{0}^{\prime})\, x\, y\, \bs{I} \\
                        \reduce{β} &λx\, y.\cn{+}_{1}^{\prime k}\, \cn{0}^{\prime}\, x\, y\, \bs{I} \\
                        \reduce{β} &λx\, y.\cn{k}^{\prime}\, x\, y\, \bs{I} \\
                           \synteq &λx\, y.(λx\, y\, z.x^{k-1}\, (z\, y))\, x\, y\, \bs{I} \\
                        \reduce{β} &λx\, y.x^{k-1}\, (\bs{I}\, y) \\
                      \contract{β} &λx\, y.x^{k-1}\, y \\
                           \synteq &\cn{k-1}
\end{align*}

Teniendo la codificación del predecesor se puede plantear una codificación de la resta, después de todo, restar $ n $ de $ m $ es aplicar la función predecesor $ n $ veces a $ m $.
\begin{equation}
  \label{eq:numeral:sub2}
  \cn{-} \synteq λm\, n.n\, \cn{-}_{1}\, m
\end{equation}
Para corroborar que esta definición es correcta, se reduce la aplicación $ (\cn{-}\, \cn{m}\, \cn{n}) $ la cuál deberá resultar en la codificación del número $ m-n $.
\begin{align*}
  \cn{-}\, \cn{m}\, \cn{n} &\synteq (λm\, n.n\, \cn{-}_{1}\, m)\, \cn{m}\, \cn{n} \\
                           &\reduce{β} \cn{n}\, \cn{-}_{1}\, \cn{m} \\
                           &\reduce{β} \cn{-}_{1}^{n}\, \cn{m} \\
                           &\synteq \cn{-}_{1}^{n-1}\, (\cn{-}_{1}\, \cn{m}) \\
                           &\reduce{β} \cn{-}_{1}^{n-1}\, \cn{m-1} \\
                           &... \\
                           &\reduce{β} \cn{-}_{1}^{n-n}\, \cn{m-n} \\
                           &\synteq \cn{m-n}
\end{align*}

La idea de definir operaciones aritméticas complejas en función de otras más sencillas también puede ser aplicada a la definición de la división. Sin embargo, no podemos definir $ m/n $ como $ (\cn{n}\, (\cn{-}\, \cn{m})\, \cn{0}) $ ya que el procedimiento de reducción consistiría en primero calcular $ m-0 = m $, después calcular $ m-m = 0 $, después calcular $ m-0=m $, y así sucesivamente hasta dejar de repetir el procedimiento. En pocas palabras, $ (\cn{n}\, (\cn{-}\, \cn{m})\, \cn{0}) $ se reduce a $ \cn{m} $ cuando $ \cn{n} $ es impar y a $ \cn{0} $ cuando $ \cn{n} $ es par.

La idea de definir la división como repetición de restas se puede interpretar considerando el siguiente ejemplo. El resultado de dividir a 12 en 3 es 4 porque 4 es la \emph{cantidad} de veces que hay que restarle al 12 el 3 hasta llegar al cero:
\[ 12-3-3-3-3=12-4\times 3=12-12=0 \]
Esto presenta un aumento de complejidad en la codificación de la operación, no solo se debe restar hasta llegar a $ \cn{0} $, también se debe mantener un conteo de la cantidad de veces que se ha restado.

Para el caso de la función logaritmo, el problema es similar a la división. El resultado de calcular el logaritmo base 3 de 81 es 4 porque 4 es la cantidad de veces que hay que dividir al 81 en 3 hasta llegar al 1 (el caso trivial para la división):
\[ (((81/3)/3)/3)/3 = 81/3^{4} = 81/81 = 1 \]

Para el caso de la función raíz, el problema es aún más grande que con la división y el logaritmo. Ya que $ \sqrt[n]{m} $ es calculada como la base a la que debemos elevar por $ n $ para obtener $ m $. Poniendo el mismo ejemplo que con el logaritmo, la idea de la raíz es partir del $ 81 $ y el $ 4 $ y calcular el número al que se tiene que dividir $ 81 $, $ 4 $ veces, hasta llegar al $ 1 $. El problema con esto es que no se puede reducir el problema a uno más sencillo basándonos únicamente en contar y en la operación de división. Sin embargo, es posible utilizar métodos de aproximación y calcular $ \sqrt[4]{81} $ intentando divisiones entre 1 y fallar, luego entre 2 y fallar, luego entre 3 y encontrar que es la respuesta.

En la siguiente subsección se construye la manera en la que se podrán plantear mecanismos más complejos de cómputo y lograr definir las operaciones de división, logaritmo y raíz.



\subsection{Iteración}
\label{sec:iteracion}

La técnica de utilizar los números naturales como mecanismo de repetición es de mucha utilidad. En el diseño de algoritmos, la repetición es usualmente representada con mecanismos de \emph{iteración}, usualmente en cada paso de la iteración una o más variables en el contexto del algoritmo cambian, hasta obtener en una de ellas el resultado final.

Por ejemplo, un algoritmo para computar el factorial de un número $ n $ puede ser expresado de manera iterativa como:

\begin{algorithm}
  \caption{Factorial de $ n $}
  \label{alg:factorial}
  \begin{algorithmic}
    \REQUIRE $ n \in \mathbb{N} $
    \ENSURE $ n! $
    \STATE $ r \leftarrow copia(n) $
    \STATE $ a \leftarrow 1 $
    \WHILE{$ r \centernot= 0 $}
    \STATE $ a \leftarrow a \times r $
    \STATE $ r \leftarrow r - 1 $
    \ENDWHILE
    \RETURN $ a $
  \end{algorithmic}
\end{algorithm}

El mecanismo utilizado en este algoritmo para iterar es el \emph{mientras}, éste se acompaña con una condición, si la condición se satisface, el cuerpo del \emph{mientras} es ejecutado, de lo contrario, se detiene la iteración y se prosigue con el resto de los pasos del algoritmo.

Por fortuna, este tipo de algoritmos pueden ser codificados de manera sencilla en el cálculo $ λ $. En lugar de codificar el \emph{mientras}, se puede utilizar $ \cn{n} $ para repetir un procedimiento, después de todo, el algoritmo inicia con $ r = n $ y en cada iteración $ r $ disminuye en 1, por lo que se realizan $ n $ iteraciones. La variable $ a $ inicia en 1 y en cada iteración es multiplicada por $ r $, al terminar los pasos del algoritmo, el valor de $ a $ es el resultado $ n! $.

La clave para codificar este algoritmo es determinar los valores que representan el cómputo. Las variables $ r $ y $ a $ describen el estado del cómputo en el caso trivial $ n = 0 $. Cuando $ n \centernot= 0 $, en cada iteración, toda la información del cómputo sigue estando en las variables $ r $ y $ a $, aún más, los valores de estas variables describen una propiedad interesante del algoritmo: Antes y después de cada iteración, se cumple que $ n! = a \times r! $.

Ya que $ \cn{n} $ será el mecanismo de iteración, se deben determinar dos cosas: el término que será aplicado repetidas veces $ P $ y el término inicial $ B $, de tal manera que $ (\cn{n}\, P\, B) $ se $ β $-reduzca al estado final del cómputo.

El \emph{estado del cómputo} consiste de la codificación de $ r $ y $ a $ como numerales de Church. Lo que debemos codificar para representar el algoritmo es una manera de crear un estado a partir de dos números y una manera de obtener el primer y el segundo valor de un estado, es decir, el \emph{constructor} y los \emph{selectores}. Ya que son únicamente dos valores, se pueden utilizar las codificaciones $ \bs{T} $ y $ \bs{F} $ para \emph{decidir} el valor del estado que se desea obtener.

Sean $ \cn{r} $ y $ \cn{a} $ dos numerales, el término $ M \synteq λp.p\, \cn{r}\, \cn{a} $ puede representar al estado, de tal manera que $ (M\, \bs{T}) \reduce{β} \cn{r} $ y $ (M\, \bs{F}) \reduce{β} \cn{a} $.

Para construir un estado, basta con codificar un término $ λ $ que al ser aplicado a dos numerales, se reduzca a un término como $ M $. Se define el constructor $ S $ de un estado como
\begin{equation}
  \label{eq:iter:const1}
  S \synteq λn_{1}\, n_{2}.λp.p\, n_{1}\, n_{2}
\end{equation}
Para seleccionar de un determinado valor a partir de un estado, se plantean abstracciones $ λ $ que al ser aplicadas a un término como $ M $, se reduzcan al valor deseado. Se definen los selectores $ S_{r} $ y $ S_{a} $ de un estado como
\begin{equation}
  \label{eq:iter:selec1r}
  S_{r} \synteq λs.s\, \bs{T}
\end{equation}
\begin{equation}
  \label{eq:iter:selec1a}
  S_{a} \synteq λs.s\, \bs{F}
\end{equation}

Con estas codificaciones, se facilita la escritura de los términos $ P $ y $ B $. El estado inicial es $ r = n $ y $ a = 1 $, por lo que, conociéndo un numeral $ \cn{n} $, el término $ B $ se codifica como
\begin{equation}
  \label{eq:iter:base1}
  B \synteq S\, \cn{n}\, \cn{1}
\end{equation}
El término $ P $ debe ser una abstracción que sea aplicada a un estado y sea reducida a un estado, ya que en el cálculo $ λ $ no hay una noción de asignación, en cada repetición de la aplicación de $ P $ se crea un estado nuevo con sus valores en función del estado anterior. Si $ \cn{r} $ y $ \cn{a} $ son los valores del estado previo, el término $ P $ debe reducirse a un estado en donde el primer elemento sea $ (\cn{-_{1}}\, \cn{r}) $ y el segundo sea $ (\cn{\times}\, \cn{a}\, \cn{r}) $. Utilizando los selectores $ S_{r} $ y $ S_{a} $, el término $ P $ se codifica como

\begin{equation}
  \label{eq:iter:proc1}
  P \synteq λs.S\, (\cn{-}_{1}\, (S_{r}\, s))\, (\cn{\times}\, (S_{a}\, s)\, (S_{r}\, s))
\end{equation}

La codificación completa del algoritmo factorial, utilizando las definiciones \eqref{eq:iter:const1}, \eqref{eq:iter:selec1r} y \eqref{eq:iter:selec1a}, se define
\begin{equation}
  \label{eq:iter:fact1}
  \cn{!} \synteq λn.n\, (λs.S (\cn{-}_{1}\, (S_{r}\, s))\, (\cn{\times}\, (S_{a}\, s)\, (S_{r}\, s)))\, (S\, n\, \cn{1})
\end{equation}

Para poder integrar esta definición y componer expresiones algebraicas con las codificaciones de las operaciones elementales, la aplicación de $ \cn{!} $ a un numeral $ \cn{n} $ debe $ β $-reducirse al numeral $ \cn{n!} $, sin embargo, al obtener la forma normal de $ (\cn{!}\, \cn{n}) $ el resultado es un estado equivalente a $ (S\, \cn{0}\, \cn{1}) $ si $ \cn{n} \convertible{β} \cn{0} $ o a $ (S\, \cn{1}\, \cn{n!}) $ en otro caso. Por lo tanto $ \cn{!} $ debe estar codificado de tal manera que después de computar el algoritmo, seleccione el segundo elemento del estado resultante.
\begin{equation}
  \label{eq:iter:fact2}
  \cn{!} \synteq λn.S_{a}\, (n\, (λs.S\, (\cn{-}_{1}\, (S_{r}\, s))\, (\cn{\times}\, (S_{a}\, s)\, (S_{r}\, s)))\, (S\, n\, \cn{1}))
\end{equation}

Lamentablemente, no siempre es posible expresar algoritmos en donde todo el estado se resuma en dos valores. Sin embargo, utilizando una extensión similar a la \autoref{sec:boolean-extensiones} se puede generalizar la codificación de algoritmos cuyos estados tienen $ n $ componentes.

Sean $ {}_{n}v_{1}, {}_{n}v_{2}, ..., {}_{n}v_{n} $, términos de la forma

\[ {}_{n}v_{i} \synteq λx_{1}\, ...\, x_{n}.x_{i} \]

El constructor $ {}_{n}S $ de un estado con $ n $ valores se define como
\begin{equation}
  \label{eq:state-cons}
  {}_{n}S \synteq λx_{1}\, ...\, x_{n}.λp.p\, x_{1}\, ...\, x_{n}
\end{equation}
El selector del $ i $-ésimo valor de un estado, se define
\begin{equation}
  \label{eq:state-selec}
  {}_{n}S_{i} \synteq λs.s\, v_{i}
\end{equation}

La codificación de las operaciones aritméticas de división, logaritmo y raíz, serán basadas en algoritmos similares al del factorial. Para tener la habilidad de escribir algoritmos aritméticos, es necesario complementar los numerales de Church con predicados, por ejemplo, para determinar si un numeral es cero o si dos numerales son iguales.

El primer predicado que se define es el que a partir de un numeral $ \cn{n} $, determina si es el $ \cn{0} $. Este predicado es muy utilizado ya que en muchos algoritmos, la condición de paro es cuando un valor numérico tiene el valor cero. A partir de la estructura de $ \cn{n} \synteq (λx\, y.x^{n}\, y) $ se puede encontrar una manera de aplicarle dos términos $ P $ y $ Q $ a $ \cn{n} $, tal que al reducirse resulte en $ \bs{T} $ si $ n=0 $ y a $ \bs{F} $ si $ n>0 $. El $ \cn{0} $ no tiene aplicaciones internas y simplemente es reducido al segundo término al que fue aplicado, por lo tanto $ (\cn{n}\, P\, \bs{T}) $ debe reducirse a $ \bs{T} $ cuando $ n=0 $. Cuando el numeral es mayor a cero, la primera aplicación de $ (P\, \bs{T}) $ debe reducirse a $ \bs{F} $ y las siguientes aplicaciones deben ser $ (P\, \bs{F}) $ y reducirse también a $ \bs{F} $. Un término que al ser aplicado a cualquier término es reducido a $ \bs{F} $ es $ (\bs{K}\, \bs{F}) $. Por lo tanto, la codificación de este predicado se define
\begin{equation}
  \label{eq:numeral:pred0}
  \cn{0}_{?} \synteq λn.n\, (\bs{K}\, \bs{F})\, \bs{T}
\end{equation}

Para corroborar que este predicado es correcto al ser aplicado a un numeral, se reducen las siguientes aplicaciones:
\begin{align*}
  \cn{0}_{?}\, \cn{0} \synteq &(λn.n\, (\bs{K}\, \bs{F})\, \bs{T})\, \cn{0} \\
                \contract{β} &\cn{0}\, (\bs{K}\, \bs{F})\, \bs{T} \\
                  \reduce{β} &(\bs{K}\, \bs{F})^{0}\, \bs{T} \\
                     \synteq &\bs{T} \\
  \cn{0}_{?}\, \cn{n} \synteq &(λn.n\, (\bs{K}\, \bs{F})\, \bs{T})\, \cn{n} \\
                \contract{β} &\cn{n}\, (\bs{K}\, \bs{F})\, \bs{T} \\
                  \reduce{β} &(\bs{K}\, \bs{F})^{n}\, \bs{T} \\
                     \synteq &(\bs{K}\, \bs{F})^{n-1}\, (\bs{K}\, \bs{F}\, \bs{T}) \\
                  \reduce{β} &(\bs{K}\, \bs{F})^{n-1}\, \bs{F} \\
                     \synteq &(\bs{K}\, \bs{F})^{n-2}\, (\bs{K}\, \bs{F}\, \bs{F}) \\
                  \reduce{β} &(\bs{K}\, \bs{F})^{n-2}\, \bs{F} \\
                          ...& \\
                  \reduce{β} &(\bs{K}\, \bs{F})^{n-n}\, \bs{F} \\
                     \synteq &\bs{F}
\end{align*}

El siguiente predicado que se define es el que a partir de dos numerales $ \cn{m} $ y $ \cn{n} $, determina si $ m \leq n $. La codificación de este predicado se basa en la observación de al restar $ \cn{n} $ de $ \cn{m} $ el resultado será $ \cn{0} $ si $ \cn{m} $ es menor o igual a $ \cn{n} $. Por lo tanto, la codificación de este predicado se define
\begin{equation}
  \label{eq:numeral:predleq}
  \cn{\leq}_{?} \synteq λm\, n.\cn{0}_{?}\, (\cn{-}\, m\, n)
\end{equation}

Ya que estos predicados son reducidos a valores booleanos cuando se aplican a numerales de Church, pueden ser combinados utilizando las operaciones del álgebra booleana. Otros predicados pueden codificarse haciéndo uso de propiedades numéricas.
\begin{itemize}
\item Si $ n \leq m $, entonces $ m \geq n $:
  \begin{equation}
    \label{eq:numeral:predgeq}
    \cn{\geq}_{?} \synteq λm\, n.\cn{\leq}_{?}\, n\, m
  \end{equation}
\item Si $ m \leq n $ y $ m \geq n $, entonces $ m = n $:
  \begin{equation}
    \label{eq:numeral:predeq}
    \cn{=}_{?} \synteq λm\, n.\bs{\land}\, (\cn{\leq}_{?}\, m\, n)\, (\cn{\geq}_{?}\, m\, n)
  \end{equation}
\item Si $ m \centernot\leq n $, entonces $ m > n $:
  \begin{equation}
    \label{eq:numeral:predgt}
    \cn{>}_{?} \synteq λm\, n.\bs{\lnot}\, (\cn{\leq}_{?}\, m\, n)
  \end{equation}
\item Si $ m \centernot\geq n $, entonces $ m < n $:
  \begin{equation}
    \label{eq:numeral:predlt}
    \cn{<}_{?} \synteq λm\, n.\bs{\lnot}\, (\cn{\geq}_{?}\, m\, n)
  \end{equation}
\end{itemize}

A la vez, a partir de estos predicados se pueden definir otros términos muy utilizados en algoritmos aritméticos:

\begin{itemize}
\item Si $ m < n $, entonces $ min(m,n)=m $, de lo contrario $ min(m,n)=n $:
  \begin{equation}
    \label{eq:numeral:min}
    \cn{min} \synteq λm\, n.\bs{\prec}\, (\cn{<}_{?}\, m\, n) m\, n
  \end{equation}
\item Si $ m > n $, entonces $ max(m,n)=m $, de lo contrario $ max(m,n)=n $:
  \begin{equation}
    \label{eq:numeral:max}
    \cn{max} \synteq λm\, n.\bs{\prec}\, (\cn{>}_{?}\, m\, n) m\, n
  \end{equation}
\end{itemize}

Para codificaciones de $ \cn{min} $ y $ \cn{max} $ que se reduzcan correctamente al ser aplicados a más de dos numerales, se puede utilizar una técnica como la mostrada en la \autoref{defn:op-bool-bin-lambda}.

Con estos nuevos términos, es más amena la codificación de algoritmos, de hecho, la manera de codificarlos es casi tan sencillo como programar los algoritmos en lenguajes aptos para la programación funcional como \texttt{Lisp}, \texttt{ML} o \texttt{Haskell}.

La estrategia general para la codificación de las operaciones faltantes se basa en la observación de que la sustracción es la función inversa de la adición, la división es la función inversa de la multiplicación y el logaritmo y la raíz son las inversas de la exponenciación. Sean $ m $, $ n $ y $ k $ tres números naturales
\begin{align*}
  m-n = x &\iff m = x+n \\
  m/n = x &\iff m = x\times n\\
  \log_{n}m = x &\iff m = n^{x} \\
  \sqrt[n]m = x &\iff x^{n}
\end{align*}
Estas operaciones deben de ser tratadas con mucho cuidado ya que no son operaciones cerradas, es decir, existen números naturales $ m $ y $ n $ tal que, para alguna operación $ \odot $ de las cuatro mencionadas, $ m \odot n $ no es un número natural. Por ejemplo, con la sustracción se pueden calcular números negativos, con la división números racionales, con la raíz números reales y con el logaritmo no únicamente números reales, también el valor $ -\infty $. Por lo tanto, las codificaciones que se definen, serán versiones discretas, cerradas y por lo tanto inexactas de las que usualmente se utilizan.

El algoritmo en el que se basan estas cuatro operaciones considera dos números $ m $ y $ n $; una operación inversa $ \odot $; una condición de trivialidad $ {\rm err} $; y un valor de trivialidad $ t $. La idea del algoritmo es regresar $ t $ cuando $ {\rm err}(m,n) $ es verdadero, de lo contrario iterar a partir de $ x = 0 $, calculando el resultado $ x \odot n $ hasta obtener un valor mayor o igual a $ m $, en donde $ x $ será el cálculo de la operación.

\begin{algorithm}
  \caption{Cálculo de $ m \odot^{\, -1} n $}
  \label{alg:inversas}
  \begin{algorithmic}
    \REQUIRE $ m,\ n,\ t \in \mathbb{N},\ \odot \colon \mathbb{N} \times \mathbb{N} \to \mathbb{N},\ err \colon \mathbb{N} \times \mathbb{N} \to \{ \mathrm{verdadero},\ \mathrm{falso} \} $
    \ENSURE $ m \odot^{\, -1} n $
    \IF{$ err(m,n) $}
    \RETURN $ t $
    \ELSE
    \STATE $ x \leftarrow 0 $
    \STATE $ a \leftarrow x \odot n $
    \WHILE{$ a < m $}
    \STATE $ a \leftarrow x \odot n $
    \STATE $ x \leftarrow x + 1 $
    \ENDWHILE
    \RETURN $ a $
    \ENDIF
  \end{algorithmic}
\end{algorithm}

Para la sustracción la condición de trivialidad es $ m \leq n $ y el valor de trivialidad $ 0 $. Para la división la condición de trivialidad es $ m < n $ y el valor de trivialidad $ 1 $. Para el logaritmo la condición de trivialidad es $ m=0 $ y el valor de trivialidad $ 0 $. Para la raíz la condición de trivialidad es $ n=0 $ y el valor de trivialidad $ 1 $.

Una limitación que tiene la iteración en base a los numerales es que se debe conocer la cantidad de veces que se repetirá un proceso, en el caso del \autoref{alg:inversas}, la condición de paro es verificada de manera dinámica, mientras cuando los cálculos se están realizando. Sin embargo, es posible establecer una cota superior a la cantidad de pasos en base a las propiedades de las operaciones establecidas.

En el caso de la sustracción, $ m-n $ debe ser un número natural, y ya que la iteración sucede cuando $ m>n $, entonces $ x\leq m $. En el caso de la división, $ m/n $ debe ser un número natural, y ya que la iteración sucede cuando $ m\geq n $, entonces $ x\leq m $. En el caso del logaritmo, $ \log_{n}m $ debe ser un número natural, y ya que la iteración sucede cuando $ m\geq n $, entonces $ x\leq m $. En el caso de la raíz, ya que $ m $, $ n $ y $ x $ siempre serán naturales, y la iteración sucede cuando $ n \centernot= 0 $, entonces $ x\leq m $. Por lo tanto, se puede utilizar a $ m $ para determinar la cantidad de iteraciones, de tal manera que cuando la condición $ a < m $ se cumpla, siempre se reduzca al valor de $ a $. El \autoref{alg:inversas2} es una modificación del \autoref{alg:inversas} para que su codificación sea más directa.

\begin{algorithm}
  \caption{Cálculo de $ m \odot^{\, -1} n $}
  \label{alg:inversas2}
  \begin{algorithmic}
    \REQUIRE $ m,\ n,\ t \in \mathbb{N},\ \odot \colon \mathbb{N} \times \mathbb{N} \to \mathbb{N},\ err \colon \mathbb{N} \times \mathbb{N} \to \{ \mathrm{verdadero},\ \mathrm{falso} \} $
    \ENSURE $ m \odot^{\, -1} n $
    \IF{$ err(m,n) $}
    \RETURN $ t $
    \ELSE
    \STATE $ x \leftarrow 0 $
    \STATE $ a \leftarrow x \odot n $
    \FOR{iteraciones \TO $ m $}
    \IF{$ a < m $}
    \STATE $ a \leftarrow x \odot n $
    \STATE $ x \leftarrow x + 1 $
    \ELSE
    \STATE $ a \leftarrow a $
    \ENDIF
    \ENDFOR
    \RETURN $ a $
    \ENDIF
  \end{algorithmic}
\end{algorithm}

Para acortar la definición de la codificación del algoritmo de inversa, se definen los siguientes términos auxiliares:
\begin{align*}
  \bs{:} &\synteq {}_{2}S \\
  \bs{A} &\synteq {}_{2}S_{1} \\
  \bs{X} &\synteq {}_{2}S_{2}
\end{align*}

La codificación del \autoref{alg:inversas2} es
\begin{align}
  \label{eq:numeral:inversas}
  \cn{\odot}^{\, -1} \synteq λ\odot\, e\, t.λm\, n.\bs{\prec}\, (e\, m\, n) \ \ \ \ \ \ \ \ \ &\\
  t \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &\nonumber \\
  (\bs{X}\, (m\, (λs.\bs{\prec}\, &(\cn{<}_{?}\, (\bs{A}\, s)\, m)\nonumber \\
  &(\bs{:}\, (\odot\, (\bs{X}\, s)\, n)\, (\cn{+}_{1}\, (\bs{X}\, s)))\nonumber \\
  &(\bs{:}\, (\bs{A}\, s)\, (\bs{X}\, s)))\nonumber \\
  (\bs{:}\, (\odot\, \cn{0}&\, n)\, \cn{0})))\nonumber
\end{align}

La definición es difícil de leer y comprender si se escribe en un solo renglón, por ello, se utilizaron varios renglones para escribir el término, la convención para escribirlo fue: los saltos de renglón se dan en cada término condicional para que la condición esté en el mismo renglón que $ \bs{\prec} $, el consecuente en el siguiente renglón horizontalmente alineado con la condición y la alternativa en el siguiente renglón horizontalmente alineado con el consecuente. También hay un salto de renglón en la aplicación de $ m $, de tal manera que los dos términos a los que es aplicado estén alineados horizontalmente.

Utilizando el término $ \cn{\odot}^{\, -1} $ y las condiciones y valores de trivialidad mencionados anteriormente, se definen las codificaciones de las funciones inversas
\begin{equation}
  \label{eq:numeral:subs-inv}
  \cn{-} \synteq \cn{\odot}^{\, -1}\, \cn{+}\, \cn{\leq}_{?}\, \cn{0}
\end{equation}
\begin{equation}
  \label{eq:numeral:div-inv}
  \cn{/} \synteq \cn{\odot}^{\, -1}\, \cn{\times}\, \cn{<}_{?}\, \cn{1}
\end{equation}
\begin{equation}
  \label{eq:numeral:log-inv}
  \cn{\log} \synteq \cn{\odot}^{\, -1}\, \cn{\uparrow} (λm\, n.\cn{0}_{?}\, m) \cn{0}
\end{equation}
\begin{equation}
  \label{eq:numeral:root-inv}
  \cn{\mathrm{root}} \synteq \cn{\odot}^{\, -1} (λx\, n.\cn{\uparrow}\, n\, x) (λm\, n.\cn{0}_{?}\, n) \cn{1}
\end{equation}

El \autoref{alg:inversas2} describe un método de aproximación bastante pobre e ineficiente, sin embargo, es posible codificar otras maneras de calcular estas operaciones utilizando las técnicas vistas hasta el momento, siempre y cuando se establezca una cota superior antes de realizar las iteraciones.

\subsection{Hiperoperaciones}
\label{sec:hiperoperaciones}

Las definiciones \eqref{eq:numeral:sum2}, \eqref{eq:numeral:mul2}, \eqref{eq:numeral:exp2} describen de manera clara y consisa la relación entre la adición, la multiplicación y la exponenciación. Conociendo una cantidad de repeticiones, una operación de agregación y el valor neutro de dicha agregación, fué posible definir una operación aritmética en función de otra operación más simple, hasta tener el caso base con la adición.

En el artículo ``Mathematics and Computer Science: Coping with Finiteness'' \cite{Knuth:Arrow}, Donald E. Knuth introduce la notación de flecha para expresar números finitos gigantescos. La notación de flecha ya fue utilizada en el término de la exponenciación, ya que, de acuerdo a Knuth, $ x \mathbin{\uparrow} n = x^{n} $.

La definición de la notación de flecha es la siguiente:
\begin{align*}
  x \mathbin{\uparrow} n &= x^{n} \\
  x \mathbin{\uparrow^{k}} n = x \underbrace{\uparrow ... \uparrow}_\text{$ k $ flechas} n &= \underbrace{(x \overbrace{\uparrow ... \uparrow}^\text{$ k-1 $ flechas} (x \overbrace{\uparrow ... \uparrow}^\text{$ k-1 $ flechas} (\cdots \overbrace{\uparrow ... \uparrow}^\text{$ k-1 $ flechas} x) \cdots))}_\text{$ n $ veces}
\end{align*}

Esta notación introduce una secuencia infinita de operaciones cuya definición es recursiva y consistente con las definiciones de la adición, multiplicación y exponenciación presentadas. Sea $ \cn{\mc{H}(i)} $ el $ i $-ésimo elemento de esta secuencia
\begin{align}
  \label{eq:hyper}
  \cn{\mc{H}(1)} \synteq \cn{\uparrow} &\synteq (λm\, n.n\, (\cn{\times}\, m)\, \cn{1}) \\
  \cn{\mc{H}(i)} \synteq \cn{\uparrow}_{i} &\synteq (λm\, n.n\, (\cn{\mc{H}(i-1)}\, m)\, \cn{1}) \nonumber
\end{align}
El valor neutro siempre es $ \cn{1} $ ya que, para todo $ k > 1 $
\[ x \mathbin{\uparrow^{k}} 1 = x \mathbin{\uparrow^{k-1}} 1 \]
El primer paso para codificar estas secuencia es generalizar la estructura del término $ \cn{\uparrow} $. Ya que en la definición \eqref{eq:hyper} lo único que cambia en la estructura es la operación previa, se puede colocar una variable enlazada $ f $ que denote la operación anterior. De esta manera, la codificación de un término que dada una codificación de $ \mc{H}(i) $ es reducido a $ \mc{H}(i+1) $ es
\[ λf.λm\, n.n(f\, m) \cn{1} \]
Se definen los términos $ \cn{\uparrow}_{i} $ de la siguiente manera
\begin{align*}
  \cn{\uparrow}_{1} &\synteq (λf.λm\, n.n\, (f\, m)\, \cn{1})\, \cn{\times}\, \reduce{β} λm\, n.n\, (\cn{\times}\, m)\, \cn{1} \\
  \cn{\uparrow}_{2} &\synteq (λf.λm\, n.n\, (f\, m)\, \cn{1})\, \cn{\uparrow}_{1} \reduce{β} λm\, n.n\, (\cn{\uparrow}_{1}\, m)\, \cn{1} \\
                    &...\\
  \cn{\uparrow}_{i} &\synteq (λf.λm\, n.n\, (f\, m)\, \cn{1})\, \cn{\uparrow}_{i-1} \reduce{β} λm\, n.n\, (\cn{\uparrow}_{i-1}\, m)\, \cn{1}
\end{align*}
Este procedimiento es correcto, sin embargo, en caso que se requiera utilizar el término $ \cn{\uparrow}_{1000} $ se deberán de escribir manualmente las definiciones de $ \cn{\uparrow}_{999} $ hasta $ \cn{\uparrow}_{1} $ lo cuál es inconveniente y tedioso. Con las técnicas que se han desarrollado previamente, se puede construir un término que dado un numeral $ \cn{n} $, se $ β $-reduzca al $ n $-ésimo operador de la secuencia, es decir, codificar $ \cn{\mc{H}} $, tal que $ (\cn{\mc{H}}\, \cn{n}) \reduce{β} \cn{\mc{H}(n)} $ donde
\begin{equation}
  \label{eq:hyper-flow}
  \cn{\mc{H}} \synteq λn.n (λf.λm\, n.n(f\, m) \cn{1}) \cn{\times}
\end{equation}

Para corroborar que la ecuación \eqref{eq:hyper-flow} es correcta, se computan las reducciones
\begin{align*}
  \cn{\mc{H}}\, \cn{1} &\synteq (λn.n\, (λf.λm\, n.n\, (f\, m)\, \cn{1})\, \cn{\times})\, \cn{1} \\
                       &\contract{β} \cn{1}\, (λf.λm\, n.n\, (f\, m)\, \cn{1})\, \cn{\times} \\
                       &\reduce{β} (λf.λm\, n.n\, (f\, m)\, \cn{1})\, \cn{\times} \\
                       &\contract{β} λm\, n.n\, (\cn{\times}\, m)\, \cn{1} \synteq \cn{\uparrow} \synteq \cn{\uparrow}_{1}
\end{align*}

\begin{align*}
  \cn{\mc{H}}\, \cn{i} &\synteq (λn.n\, (λf.λm\, n.n\, (f\, m)\, \cn{1})\, \cn{\times})\, \cn{i} \\
                       &\contract{β} \cn{i}\, (λf.λm\, n.n\, (f\, m)\, \cn{1})\, \cn{\times} \\
                       &\reduce{β} (λf.λm\, n.n\, (f\, m)\, \cn{1})^{i}\, \cn{\times} \\
                       &\synteq (λf.λm\, n.n\, (f\, m)\, \cn{1})^{i-1}\, ((λf.λm\, n.n\, (f\, m)\, \cn{1})\, \cn{\times}) \\
                       &\contract{β} (λf.λm\, n.n\, (f\, m)\, \cn{1})^{i-1}\, (λm\, n.n\, (\cn{\times}\, m)\, \cn{1}) \\
                       &\synteq (λf.λm\, n.n\, (f\, m)\, \cn{1})^{i-1}\, \cn{\uparrow}_{1} \\
                       &... \\
                       &\reduce{β} (λf.λm\, n.n\, (f\, m)\, \cn{1})^{i-i}\, \cn{\uparrow}_{i} \synteq \cn{\uparrow}_{i}
\end{align*}

Ejemplos de reducciones concretas no serán dados debido a la naturaleza de la secuencia, tan solo $ 5 \mathbin{\uparrow\uparrow} 3 $ tiene 2185 dígitos y $ 5 \mathbin{\uparrow\uparrow} 4 $ tiene $ 1335740483872137\times 10^{2169} $ dígitos.

\section{Procesos recursivos}
\label{sec:procesos-recursivos}

Para complementar el mecanismo de iteración presentado en la \autoref{sec:iteracion}, se plantea la manera de codificar algoritmos que describen procesos \emph{recursivos}.

La recursividad está detrás de una gran cantidad de definiciones, problemas y algoritmos en matemáticas y ciencias de la computación. La idea básica de la recursividad es plantear un concepto en términos de sí mismo \cite{knuth:Concrete}.

Un ejemplo de definición recursiva es el de términos $ λ $. Una aplicación es un término y se compone de otros dos términos, mientras que una abstracción es un término y se compone de un átomo y otro término. Incluso la definición de los números naturales, los cuales nos permiten iterar, es recursiva, ya que $ (x^{n}\, y) $ es definido como un abuso de notación de $ (x\, (x^{n-1}\, y)) $.

Hay problemas clásicos cuyas soluciones son también recursivas, por ejemplo, el rompecabezas de \emph{las torres de Hanoi} o el problema de \emph{Flavio Josefo} \cite{knuth:Concrete}. Sus soluciones consisten en suponer que el problema ya fue resuelto para una versión más simple y resolver la diferencia del problema simple al original. De esta manera, se reduce el problema hasta llegar a una versión muy simple, en donde la solución es ``trivial''.

Los algoritmos con definiciones recursivas en algunos casos son más concisos que sus contrapartes iterativas. En particular cuando los algoritmos manipulan estructuras definidas de manera recursiva, su especificación suele seguir un patrón similar a la de las estructuras que manipula. Por ejemplo, los procedimientos para encontrar los subtérminos de un término $ λ $ o calcular su longitud, por la \autoref{defn:longitud} y la \autoref{defn:subtermino}, son recursivos.

El mecanismo de iteración presentado en este trabajo está más asociado al concepto de iteración en matemáticas que en computación. La estructura de los numerales de Church, capturan la idea de la aplicación de una \emph{función iterativa} cuyo dominio y rango son el mismo conjunto, de tal manera que estas funciones se pueden componer consigo mismas.

En computación, el concepto de iteración es usualmente asociado a la manera en cómo se expresa un procedimiento; la distinción entre la iteración y otros mecanismos para codificar algoritmos se vuelve entonces en una cuestión lingüística, describiendo así la iteración con palabras como \emph{repetir mientras} o \emph{repetir para}. Al traducir un \emph{programa simbólico} a una secuencia de instrucciones que una máquina abstracta (como la máquina de Turing) o real (como las computadoras) pueda entender, la diferencia entre un procedimiento recursivo y uno iterativo se evapora \cite[p.~73]{Aho:Dragon} \cite{Steele:LambdaGOTO}.

\subsection{Procedimientos v.s. procesos}
\label{sec:procedimientos-procesos}

La codificación \eqref{eq:iter:fact1} del \autoref{alg:factorial} cumple con la descripción mencionada de procedimiento recursivo. Se tiene un valor numérico que se desea calcular y para encontrarlo se emplea una abstracción que parte de un estado con una solución parcial, esta abstracción sólo debe realizar dos operaciones aritméticas para encontrar otra solución parcial más cercana a la respuesta y delegar el trabajo de computar el resto a otra abstracción que realizará lo mismo.

Un algoritmo que describe de manera más precisa la manera con como \eqref{eq:iter:fact1} se reduce es:

\begin{algorithm}
  \caption{Procedimiento $ \mathrm{factorial}(n,r,a) $}
  \label{alg:factorial2}
  \begin{algorithmic}
    \REQUIRE $ n,\ r,\ a\in \mathbb{N} $, inicialmente $ r=n $ y $ a=1 $
    \ENSURE $ n! = a\times r! $
    \IF{$ r=0 $}
    \RETURN $ a $
    \ELSE
    \RETURN $ \mathrm{factorial}(n,r-1,a\times r) $
    \ENDIF
  \end{algorithmic}
\end{algorithm}

A pesar de poder escribir un procedimiento iterativo y otro recursivo para el cálculo del factorial, los dos algoritmos describen el mismo \emph{proceso computacional}. Estos procesos no son definidos a partir del lenguaje utilizado para describir el algoritmo, si no a partir de las acciones que se realizan para computar el resultado \cite{AbelsonSussman:Wizard}. Tanto el \autoref{alg:factorial} como el \autoref{alg:factorial2} como la codificación \eqref{eq:iter:fact1} describen el mismo proceso computacional.

Un tercer algoritmo para el cálculo del factorial es el \autoref{alg:factorial3}. A pesar de ser expresado como un procedimiento recursivo al igual que el \autoref{alg:factorial2}, no describe el mismo proceso computacional.

\begin{algorithm}
  \caption{Procedimiento $ \mathrm{factorial}(n) $}
  \label{alg:factorial3}
  \begin{algorithmic}
    \REQUIRE $ n\in \mathbb{N} $
    \ENSURE $ n! $
    \IF{$ n=0 $}
    \RETURN $ 1 $
    \ELSE
    \RETURN $ n\times \mathrm{factorial}(n-1) $
    \ENDIF
  \end{algorithmic}
\end{algorithm}

Los dos procesos mostrados comparten ciertas características:

\begin{itemize}
\item Realizan la misma cantidad de multiplicaciones y restas en cada paso iterativo/recursivo;
\item Realizan una cantidad de operaciones proporcional al $ n $;
\item En cada paso iterativo/recursivo, una solución parcial al problema es calculada.
\end{itemize}

La diferencia fundamental entre estos los dos procesos es que en los Algoritmos \ref{alg:factorial}, \ref{alg:factorial2} y en la codificación \eqref{eq:iter:fact1}, en cada paso se conoce el estado completo; mientras que en el \autoref{alg:factorial3}, al realizar el paso recursivo, se pierde la información de lo que ya se ha computado.

Así como se distinguen los procedimientos recursivos de los iterativos por la manera en como son expresados. Los procesos también se pueden distinguir en recursivos e iterativos. En general, un proceso iterativo es aquel en donde el estado puede ser capturado por una cantidad fija de valores, junto con una regla fija que describe como estos valores evolucionan a lo largo del cómputo. Por otro lado, los procesos recursivos suspenden el cálculo de las operaciones hasta tener todos los valores necesarios para computar el resultado \cite{AbelsonSussman:Wizard}.

Desde un aspecto operativo, el proceso recursivo del factorial multiplica una vez que el subproblema ha sido resuelto, mientras que el proceso iterativo del factorial, multiplica conforme los subproblemas son resueltos.

\subsection{Derivación de un mecanismo de recursividad}
\label{sec:deriv-recursividad}

Las técnicas para la codificación de algoritmos que se han tratado hasta este punto, sirven para aquellos que describen un proceso iterativo. En esta sección se aborda la manera en la que se pueden codificar algoritmos que describen procesos recursivos. Para desarrollar esta técnica, se considera como ejemplo la definición recursiva de la función factorial:
\[ n! =
  \begin{cases}
    1 &n=0;\\
    n\times (n-1)! &n>0.
  \end{cases}
\]

Todas las componentes de ésta definición están codificadas, ya sea como expresiones booleanas o como expresiones aritméticas. Una pseudo-definición de esta codificación es:
\begin{align}
  \label{eq:fact1}
  \cn{!} \synteq λn.(\bs{\prec}\ &(\cn{0}_{?}\, n) \\
                                 &\cn{1} \nonumber \\
                                 &(\cn{\times}\, n\, (\cn{!}\, (\cn{-}_{1}\, n)))) \nonumber
\end{align}

El problema con esta definición es que antes de definir $ \cn{!} $, se hace referencia a ella en $ (\cn{!}\, (\cn{-}_{1}\, n)) $, por lo que no es posible establecer el valor del término factorial antes de terminar de escribir su definición.

Hay algunos trucos que se pueden implementar para simular que se tiene definida la codificación de factorial antes de definirla. Por ejemplo, si $ \cn{!} $ fuera una abstracción la cual espera ser aplicada a sí misma y a un número, pudiera definirse exactamente como \eqref{eq:fact1}, pero con una variable enlazada $ f $ que será sustituída por el término $ \cn{!} $ dentro de la definición.
\begin{align}
  \label{eq:fact2}
  \cn{!} \synteq λf\, n.(\bs{\prec}\ &(\cn{0}_{?}\, n) \\
                                     &\cn{1} \nonumber \\
                                     &(\cn{\times}\, n\, (f\, (\cn{-}_{1}\, n)))) \nonumber
\end{align}

El problema con \eqref{eq:fact2} es que si se reduce $ (\cn{!}\, \cn{!}\, \cn{n}) $ y $ n \centernot= 0 $, ocurre lo siguiente:
\begin{align*}
  \cn{!}\, \cn{!}\, \cn{n} &\reduce{β} (\cn{\times}\, \cn{n}\, (\cn{!}\, (\cn{-}_{1}\, \cn{n})))
\end{align*}

La multiplicación de $ \cn{n} $ debe realizarse con otro numeral, sin embargo, $ \cn{!} $ espera ser aplicado a $ \cn{!} $ y a $ (\cn{-}_{1}\, \cn{n}) $, sin embargo, en la reducción el término $ \cn{!} $ no es aplicado a sí mismo.
\[ (\ \cn{\times}\ \cn{n}\ (\ \cn{!}\ \underbrace{[\quad]}_\text{Debe de ir $ \cn{!} $}\ (\ \cn{-}_{1}\ \cn{n}\ ))\ ) \]

Para escapar de este problema, se debe de aplicar $ (f\, f\, (\cn{-}_{1}\, \cn{n})) $ en el cuerpo de la definición. El factorial modificado es
\begin{align}
  \label{eq:fact3}
  \cn{!} \synteq λf\, n.(\bs{\prec}\ &(\cn{0}_{?}\, n) \\
                                     &\cn{1} \nonumber \\
                                     &(\cn{\times}\, n\, (f\, f\, (\cn{-}_{1}\, n)))) \nonumber
\end{align}

Esta definición se escapa del problema de la definición recursiva, puede reducirse a la codificación de la función factorial aplicando
\[ \cn{!}\, \cn{!} \reduce{β} λn.(\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (\cn{!}\, \cn{!}\, (\cn{-}_{1}\, n)))) \]

En efecto, no se necesita el nombrar la abstracción con un símbolo como $ \cn{!} $ para expresar la codificación del factorial. La reducción anterior es exactamente la misma a
\begin{align*}
  \begin{array}{r@{\mskip\thickmuskip}l}
    ((λf\, n.(\bs{\prec}\ &(\cn{0}_{?}\, n) \\
                        &\cn{1} \\
                        &(\cn{\times}\, n\, (f\, f\, (\cn{-}_{1}\, n))))) \\
  (λf\, n.(\bs{\prec}\ &(\cn{0}_{?}\, n) \\
                        &\cn{1} \\
                        &(\cn{\times}\, n\, (f\, f\, (\cn{-}_{1}\, n))))))
  \end{array}
                          \quad \reduce{β} \quad
                          \begin{array}{r@{\mskip\thickmuskip}l}
                            (λn.(\bs{\prec}\, (\cn{0}_{?}\, n)\ \ \ \ \ \ \ \ \ \ \ \ \ &\\
                                            \cn{1}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ &\\
                                            (\cn{\times}\, n\ \ \ \ \ \ \ \ \ \ \ \ \ \ &\\
                            ((λf\, n.(\bs{\prec}\, &(\cn{0}_{?}\, n)\\
                                                 &\cn{1}\\
                                                 &(\cn{\times}\, n\, (f\, f\, (\cn{-}_{1}\, n)))))\\
                             (λf\, n.(\bs{\prec}\, &(\cn{0}_{?}\, n)\\
                                                 &\cn{1}\\
                                                 &(\cn{\times}\, n\, (f\, f\, (\cn{-}_{1}\, n)))))\\
                             (\cn{-}_{1}\, n)))))&
                          \end{array}
\end{align*}

\subsection{Combinador genérico de recursividad}
\label{sec:combinador-recursividad}

A pesar de tener este problema resuelto, la solución no es buena. Esta técnica obliga a que en cada algoritmo recursivo que se codifique, cada aplicación recursiva se deba tener el primer argumento aplicado a sí mismo. Lo que se necesita para tener un buen mecanismo de recursividad es separar la auto-aplicación de una codificación recursiva de la definición misma. Lo ideal es poder codificar un algoritmo similar a la definición \eqref{eq:fact2} y mediante algún procedimiento genérico, hacer que se auto-aplique el procedimiento a si mismo.

La ``factorización'' del mecanismo de recursión se puede lograr combinando la idea de la auto-aplicación de la ecuación \eqref{eq:fact3} y la idea de escribir los términos recursivos como en la ecuación \eqref{eq:fact2}.

En \eqref{eq:fact2} se esperaba que $ \cn{!} $ sea aplicado a sí mismo, sin embargo en su definición solo aplica $ f $ a $ (\cn{-}_{1}\, n) $, por lo que es conveniente tratar de reducir la aplicación de $ \cn{!} $ a $ (\cn{!}\, \cn{!}) $, de tal manera que la reducción sea
\begin{align*}
  \cn{!}\, (\cn{!}\, \cn{!}) &\synteq (λf\, n.(\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (f\, (\cn{-}_{1}\, n)))))\, (\cn{!}\, \cn{!}) \\
                           &\contract{β} λn.(\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (\cn{!}\ \cn{!}\, (\cn{-}_{1}\, n))))
\end{align*}

Esto hace que la codificación funcione en el primer paso recursivo. Sin embargo, $ (\cn{!}\ \cn{!}\, (\cn{-}_{1}\, n)) $ será reducido de tal manera que el siguiente paso recursivo no se aplique $ \cn{!} $ a si mismo.

\begin{align*}
  \cn{!}\ \cn{!}\, (\cn{-}_{1}\, n) &\synteq (λf\, n.(\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (f\, (\cn{-}_{1}\, n)))))\, \cn{!}\, (\cn{-}_{1}\, n) \\
                                 &\contract{β} (λn.(\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (\cn{!}\, (\cn{-}_{1}\, n)))))\, (\cn{-}_{1}\, n)
\end{align*}

El término $ (\cn{!}\, (\cn{-}_{1}\, n)) $ debería de ser $ (\cn{!}\ \cn{!}\, (\cn{-}_{1}\, n)) $ de nuevo para que el siguiente paso recursivo funcione.

En la \autoref{sec:expresiones} se mostró un término que es útil para este tipo de situaciones: \[ ω \synteq λx.x\, x \] La propiedad interesante de $ ω $ es que $ (ω\, ω) \reduce{β} (ω\, ω) $, que es justo lo que deseamos en nuestro mecanismo recursivo, el combinador que se necesita es uno similar a $ ω $, llamado $ ω^{\prime} $ tal que $ (ω^{\prime}\, ω^{\prime}) \reduce{β} (\cn{!} (ω^{\prime}\, ω^{\prime})) $.

Suponiendo que $ \cn{!} $ ya es una variable enlazada, el combinador $ ω^{\prime} $ debe ser una abstracción que espera ser aplicada a si misma, tiene la forma $ λω^{\prime}.M $. Ya que la reducción de $ ω^{\prime} $ aplicada a sí misma resulta en $ (\cn{!} (ω^{\prime}\, ω^{\prime})) $, $ M $ debe de ser la aplicación $ (\cn{!}\, N) $, para completar la regla de reducción $ N \synteq (ω^{\prime}\, ω^{\prime})$.
\[ ω^{\prime} \synteq λω^{\prime}.\cn{!}\, (ω^{\prime}\, ω^{\prime}) \convertible{α} λx.\cn{!}\, (x\, x) \]

Para completar la definición del mecanismo de recursividad se plantea un combinador que espere ser aplicado a un término como $ \cn{!} $ de \eqref{eq:fact2} e internamente aplique $ ω^{\prime} $ a sí misma. Este mecanismo es llamado combinador $ \bs{Y} $.
\begin{equation}
  \label{eq:recur:Y}
  \bs{Y} \synteq λf.(λx.f\, (x\, x))\, (λx.f\, (x\, x))
\end{equation}

Al aplicar el combinador $ \bs{Y} $ a la definición \eqref{eq:fact2} del factorial, se obtiene que
\begin{align*}
  \bs{Y}\, \cn{!} &\convertible{β} \cn{!}\, (\bs{Y}\, \cn{!}) \\
                  &\synteq (λf\, n.(\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (f (\cn{-}_{1}\, n))))) (\bs{Y}\, \cn{!}) \\
                  &\contract{β} λn.(\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (\bs{Y}\, \cn{!}\, (\cn{-}_{1}\, n))))
\end{align*}

Al reducir la aplicación de este término en un numeral mayor a cero se obtiene
\begin{align*}
  \begin{array}{r@{\mskip\thickmuskip}l}
    (λn.(\bs{\prec}\, &(\cn{0}_{?}\, n)\\
                      &\cn{1}\\
                      &(\cn{\times}\, n\, (\bs{Y}\, \cn{!}\, (\cn{-}_{1}\, n)))))\, \cn{n}
  \end{array}
  \quad \reduce{β} \quad
  \begin{array}{r@{\mskip\thickmuskip}l}
    (\cn{\times}\, \cn{n}\, (\bs{Y}\, \cn{!}\, (\cn{-}_{1}\, \cn{n})))
  \end{array}
\end{align*}

Es entonces que $ (\bs{Y}\, \cn{!}) $ puede ser $ β $-convertido nuevamente a $ (\cn{!}\, (\bs{Y}\, \cn{!})) $ para continuar al siguiente paso recursivo de la misma manera.

\subsection{Combinadores de punto fijo}
\label{sec:fixed-point}

Un \emph{punto fijo} de un operador o función es un objeto el cuál no cambia cuando el operador le es aplicado. Por ejemplo, la función $ f(x)=x^{2} $ tiene dos puntos fijos 0 y 1, ya que $ 0^{2} = 0 $ y $ 1^{2} = 1 $. Hay operadores que no tienen punto fijo, por ejemplo el sucesor de un número, ya que $ n+1 \centernot= n $ para toda $ n $.

El \autoref{thm:punto-fijo} es uno de los resultados básicos en el cálculo $ λ $.
\begin{thm}[Teorema de punto fijo]
  \label{thm:punto-fijo}
  $ \forall F\, \exists X \colon  F\, X \convertible{β} X $

  \begin{proof}[Demostración]
    Sea $ W\synteq λx.F\, (x\, x) $ y $ X \synteq W\, W $. Entonces
    \[ X \synteq (λx.F\, (x\, x))\, W \contract{β} F\, (W\, W) \synteq F\, X \]
  \end{proof}
\end{thm}

Esta demostración es algo peculiar ya que se inicia con $ X $ y se reduce este término a $ (F\, x) $, en lugar de partir hacer el proceso inverso. Sin embargo, la reducción presentada es válida de acuerdo a la definición de $ β $-convertibilidad.

El combinador $ \bs{Y} $ derivado en la \autoref{sec:combinador-recursividad} pertenece a una clase de combinadores interesantes llamados \emph{combinadores de punto fijo}. Estos combinadores tienen la propiedad de que al ser aplicados a cualquier término $ F $ ``encuentran'' un punto fijo para $ F $ \cite[p.~34]{HindleySeldin:LambdaCalculusAndCombinators}, es decir, si $ M $ es un combinador de punto fijo, entonces, para toda $ F $
\begin{equation}
  \label{eq:fixed:prop}
  F\, (M\, F) \convertible{β} M\, F
\end{equation}

A partir de la ecuación \eqref{eq:recur:Y}, se puede corroborar que $ \bs{Y} $ es un combinador de punto fijo de la siguiente manera
\begin{align}
  \label{eq:fixed:Ydem}
  \bs{Y}\, F &\synteq (λf.(λx.f\, (x\, x))\, (λx.f\, (x\, x)))\, F \\
             &\contract{β} (λx.F\, (x\, x))\, (λx.F\, (x\, x)) \nonumber \\
             &\contract{β} F\, ((λx.F\, (x\, x))\, (λx.F\, (x\, x))) \nonumber \\
             &\convertible{β} F\, (\bs{Y}\, F) \nonumber
\end{align}

Existen combinadores con una propiedad más fuerte que \eqref{eq:fixed:prop}. Alan Turing descubrió el combinador $ \bs{Θ} $ en 1937, su definicón es

\begin{equation}
  \label{eq:fixed:Turing}
  \begin{array}{r@{\mskip\thickmuskip}l}
    \bs{Θ} \synteq U\, U
  \end{array}
  \quad \text{donde} \quad
  \begin{array}{r@{\mskip\thickmuskip}l}
    U \synteq λu\, x.x\, (u\, u\, x)
  \end{array}
\end{equation}

La propiedad interesante de $ \bs{Θ} $ es que puede computar puntos fijos únicamente con la $ β $-reducción. Se corrobora esto de la siguiente manera

\begin{align}
  \label{eq:fixed:Udem}
  \bs{Θ}\, F &\synteq U\, U\, F \\
             &\contract{β} (λx.x\, (U\, U\, x))\, F \nonumber \\
             &\contract{β} F\, (U\, U\, F) \nonumber \\
             &\synteq F\, (\bs{Θ}\, F) \nonumber
\end{align}

Esta propiedad no la tiene $ \bs{Y} $, para realizar el último paso del desarrollo \eqref{eq:fixed:Ydem}, se tuvo que hacer una reducción inversa.

La utilidad de los combinadores de punto fijo va más allá que el de permitir la codificación de procesos recursivos. Estos combinadores son especialmente útiles para resolver el siguiente tipo de problema:

Sea $ Z $ un término $ λ $, con variables libres $ f $ y $ \vec{x} $, encuentra el término $ F $ tal que

\[ F\, \vec{M} \convertible{β} \subst{\subst{Z}{f}{F}}{\vec{x}}{\vec{M}} \]

En este planteamiento $ F $ puede no aparecer en $ Z $ y la solución es el mismo término a que si apareciera. Una instancia de este problema puede ser una reformulación de la codificación recursiva del factorial. Sea $ Z \synteq (\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (f\, (\cn{-}_{1}\, n)))) $, encuentra el término $ \cn{!} $ tal que
\[ \cn{!}\, \cn{n} \convertible{β} \subst{\subst{Z}{f}{\cn{!}}}{n}{\cn{n}} \]
\begin{proof}[Solución]
  Por la regla $ (β) $ se tiene que
  \[ \cn{!}\, \cn{n} \convertible{β} (λf\, n.\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (\cn{!}\, (\cn{-}_{1}\, n))))\, \cn{!}\, \cn{n} \]
  Por la regla $ (ν) $ se tiene que
  \[ \cn{!} \convertible{β} (λf\, n.\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (\cn{!}\, (\cn{-}_{1}\, n))))\, \cn{!} \]
  Esta ecuación tiene la forma $ A \convertible{β} (B\, A) $, al considerar a $ A $ de la forma $ (\bs{Y}\, B) $, se cumple la propiedad de \eqref{eq:fixed:prop} y por lo tanto
  \[ \cn{!} \synteq \bs{Y}\, (λf\, n.\bs{\prec}\, (\cn{0}_{?}\, n)\, \cn{1}\, (\cn{\times}\, n\, (f (\cn{-}_{1}\, n)))) \]
\end{proof}

En general, la solución para este tipo de problemas es
\begin{equation}
  \label{eq:fixed:prala}
  F\synteq \bs{Y} (λf\, \vec{x}.Z)
\end{equation}

\section{Estructuras recursivas}
\label{sec:estructuras-recursivas}

Utilizando combinadores de punto fijo como $ \bs{Y} $ y $ \bs{Θ} $ y la solución general \eqref{eq:fixed:prala} se pueden codificar procedimientos recursivos como el \autoref{alg:factorial3} del factorial. Sin embargo, los procesos recursivos se tornan más interesantes cuando la información que manipulan es también recursiva. En esta sección se muestran técnicas para codificar estructuras recursivas en el cálculo $ λ $.

Una variedad de lenguajes de programación, cuentan con un operador o función fundamental para la construcción de estructuras compuestas. Este operador usualmente es llamado \emph{cons}, el cual es una abreviación de la palabra ``construír en memoria''. Este operador toma dos objetos $ a $ y $ d $ y construye en memoria un objeto que contiene a ambos.

Matemáticamente, el objeto resultante de aplicar el operador \emph{cons} es un par ordenado. La notación que se utiliza en este trabajo para escribir el par conformado por $ a $ y $ d $ es $ \langle a : d \rangle $.

Un par ordenado no es más que un estado con dos elementos, para codificarse en el cálculo $ λ $, se deben plantear los mecanismos para construír pares y obtener sus elementos. A continuación se construyen las definiciones del constructor $ \mc{p} $ y los selectores $ \mc{a} $ y $ \mc{d} $ para el par ordenado (basadas en las definiciones \eqref{eq:state-cons} y \eqref{eq:state-selec}).

\begin{equation}
  \label{eq:cons1}
  \mc{p} \synteq λa\, d.λq.q\, a\, d
\end{equation}
\begin{equation}
  \label{eq:car1}
  \mc{a} \synteq λc.c\, (λa\, d.a)
\end{equation}
\begin{equation}
  \label{eq:cdr1}
  \mc{d} \synteq λc.c\, (λa\, d.d)
\end{equation}

Estas tres ecuaciones cumplen con las reducciones
\[ (\mc{a}\, (\mc{p}\, M\, N)) \reduce{β} M \]
\[ (\mc{d}\, (\mc{p}\, M\, N)) \reduce{β} N \]
para cualesquiera términos $ λ $ $ M $ y $ N $. Para corroborar esto, se desarrollan las reducciones:
\begin{align}
  \label{eq:car1-prop}
  \mc{a} (\mc{p}\, M\, N) &\synteq (λc.c\, (λa\, d.a))\, (\mc{p}\, M\, N) \\
                          &\contract{β} (\mc{p}\, M\, N)\, (λa\, d.a) \nonumber \\
                          &\synteq ((λa\, d.λq.q\, a\, d)\, M\, N)\, (λa\, d.a) \nonumber \\
                          &\reduce{β} (λq.q\, M\, N)\, (λa\, d.a) \nonumber \\
                          &\contract{β} (λa\, d.a)\, M\, N \nonumber \\
                          &\reduce{β} M \nonumber
\end{align}
\begin{align}
  \label{eq:cdr1-prop}
  \mc{d} (\mc{p}\, M\, N) &\synteq (λc.c\, (λa\, d.d))\, (\mc{p}\, M\, N) \\
                          &\contract{β} (\mc{p}\, M\, N)\, (λa\, d.d) \nonumber \\
                          &\synteq ((λa\, d.λq.q\, a\, d)\, M\, N)\, (λa\, d.d) \nonumber \\
                          &\reduce{β} (λq.q\, M\, N)\, (λa\, d.d) \nonumber \\
                          &\contract{β} (λa\, d.d)\, M\, N \nonumber \\
                          &\reduce{β} N \nonumber
\end{align}

En el resto de esta sección se abordan diferentes maneras en las que se puede emplear la estructura del par para construír estructuras más complejas.

\subsection{Listas}
\label{sec:estructura-listas}

Las listas son secuencias de valores, en donde cada valor en la lista tiene una posición fija. La codificación de las listas en el cálculo $ λ $ se asemeja a la lista enlazada comunmente estudiada en estructuras de datos. Si consideramos que el par ordenado contiene como primer elemento un numeral de Church y como segundo elemento otro par ordenado, se puede representar una lista de números, en donde el último par contiene como segundo elemento una codificación que represente el valor nulo $ \emptyset $.

\[ \langle \cn{n}_{1} : \langle \cn{n}_{2} : \langle \cn{n}_{3} : \langle ... \langle \cn{n}_{k} : \emptyset \rangle ... \rangle \rangle \rangle \rangle \]

Denotada de manera abreviada como

\[ \langle \cn{n}_{1},\ \cn{n}_{2},\ \cn{n}_{3},\ ...\ ,\ \cn{n}_{k} \rangle \]

La codificación de $ \emptyset $ debe elegirse con mucho cuidado. En los algoritmos que manipulan listas es crucial determinar cuando se ha llegado al final de la lista, por lo tanto se hace uso de un predicado para determinar si un determinado objeto es un par o es el valor nulo (de manera similar a la comparación de un número con el cero en los algoritmos aritméticos).

Así como el predicado $ \cn{0}_{?} $ fue construído asumiendo que sería aplicado a un numeral, el término $ \emptyset $ se construye asumiendo que será aplicado a una lista de números. Formalmente una lista de numeros, o es un par cuyo primer elemento es un numeral de Church y cuyo segundo elemento es otra lista, o es el término nulo (lista con cero elementos).

\begin{align}
  \label{eq:lis-def1}
  \mathcal{L} \longrightarrow \langle \cn{n} : \mathcal{L} \rangle \mid \emptyset
\end{align}

Por lo tanto, se espera que el predicado $ \emptyset_{?} $ sea aplicado a un término de la forma $ (λq.q\, \cn{n}\, \mc{L}) $ o al término $ \emptyset $, de tal manera que

\begin{align*}
  \emptyset_{?} (λq.q\, \cn{n}\, \mc{L}) &\reduce{β} \bs{F} \\
  \emptyset_{?} \emptyset &\reduce{β} \bs{T}
\end{align*}

Una manera de convertir un término par a $ \bs{F} $ es reduciendo la aplicación $ (\bs{K}\, \bs{F}\, (λq.q\, \cn{n}\, \mc{L})) $, sin embargo, este resultado es el mismo para cualquier valor al que se aplique $ (\bs{K}\, \bs{F}) $ y el objetivo es poder discriminar entre un par y $ \emptyset $. Se puede considerar un término similar a $ (\bs{K}\, \bs{F}) $ pero que cancele los siguientes dos términos a los que sea aplicado:
\[ (λx\, y.\bs{F})M\, N \reduce{β} \bs{F} \]
De esta manera, aplicar un par a este término resulta en la reducción
\begin{align*}
  (λq.q\, \cn{n}\, \mc{L})\, (λx\, y.\bs{F}) &\contract{β} (λx\, y.\bs{F})\, \cn{n}\, \mc{L} \\
                                             &\reduce{β} \bs{F}
\end{align*}
Por lo tanto, la codificación de $ \emptyset_{?} $ que es reducida a falso al ser aplicada a un par es
\begin{equation}
  \label{eq:lis-emptyp}
  \emptyset_{?} \synteq (λl.l\, (λx\, y.\bs{F}))
\end{equation}
Con esta definición, la propiedad que debe cumplir la codificación de $ \emptyset $ es $ (\emptyset_{?}\, \emptyset) \reduce{β} \bs{T} $, lo cuál resulta ser el término $ (\bs{K}\, \bs{T}) $ ya que
\begin{align*}
  \emptyset_{?}\, (\bs{K}\, \bs{T}) &\synteq (λl.l\, (λx\, y.\bs{F}))\, (\bs{K}\, \bs{T}) \\
                                    &\contract{β} \bs{K}\, \bs{T}\, (λx\, y.\bs{F}) \\
                                    &\reduce{β} \bs{T}
\end{align*}
Por lo tanto
\begin{equation}
  \label{eq:lis-empty}
  \emptyset \synteq \bs{K}\, \bs{T}
\end{equation}

\begin{rem}[Sobre predicados]
  La aplicación de un predicado como $ \cn{0}_{?} $ o $ \emptyset_{?} $ a un término $ λ $ $ M $ no necesariamente se $ β $-reduce a una codificación de valor de verdad. Estos predicados son construídos para ser aplicados a numerales o listas respectivamente y el resultado de reducir otro tipo de términos no es de importancia para la codificación de algoritmos.
\end{rem}

Con estas codificaciones se pueden construír algoritmos que manipulen listas de números. Consideremos el \autoref{alg:lis-doubles} que dada una lista de números compute una lista con la misma cantidad de elementos pero con cada número de la lista original multiplicado por 2. En cada paso recursivo se verifica que la lista $ \mc{L} $ no sea el valor nulo, en cuyo caso, será un par cuyo primer elemento es $ n $ y segundo elemento es otra lista $ \mc{L}^{\prime} $; se construye otro par con el primer elemento multiplicado por 2 y con el segundo elemento el resultado de realizar este mismo proceso con $ \mc{L}^{\prime} $.

\begin{algorithm}
  \caption{Procedimiento recursivo $ \mathrm{dobles}(\mc{L}) $}
  \label{alg:lis-doubles}
  \begin{algorithmic}
    \REQUIRE $ \mc{L} \in \{ \langle n_{1},\ ...\ ,\ n_{k} \rangle \mid n\in \mathbb{N} \} \cup \emptyset $
    \ENSURE $ \langle 2\times n_{1},\ ...\ ,\ 2\times n_{k} \rangle $ ó $ \emptyset $
    \IF{$ \mc{L} = \emptyset $}
    \RETURN $ \emptyset $
    \ELSE
    \STATE $ \langle n : \mc{L}^{\prime} \rangle \leftarrow \mc{L} $
    \RETURN $ \langle 2\times n : \mathrm{dobles}(\mc{L}^{\prime}) \rangle $
    \ENDIF
  \end{algorithmic}
\end{algorithm}

El predicado $ \emptyset_{?} $ es utilizado con la condicional booleana $ \bs{\prec} $  sobre la lista $ \mc{L} $. Cuando la lista sea la codificación de nulo, el resultado es nulo; de lo contrario, se asume que $ \mc{L} $ es un par y se construye el par correspondiente utilizando los términos $ \mc{p} $, $ \mc{a} $ y $ \mc{d} $. La codificación resultante es \eqref{eq:lis-doubles}.
\begin{align}
  \label{eq:lis-doubles}
  \bs{Y}\, (λf\, \mc{L}.\bs{\prec}\, (\emptyset_{?}&\, \mc{L})\\
  \emptyset\ \ \ & \nonumber \\
  (\mc{p}\  &(\cn{\times}\, \cn{2}\, (\mc{a}\, \mc{L})) \nonumber \\
                                               &(f\, (\mc{d}\, \mc{L})))) \nonumber
\end{align}
Teniendo esta codificación, es relativamente fácil generalizarla para que a cada número en la lista se le aplique algún término $ g $ dado, el cual puede ser reducido a otro número.
\begin{align}
  \label{eq:lis-map}
  \bs{Y}\, (λf\, g\, \mc{L}.\bs{\prec}\, (\emptyset_{?}&\, \mc{L})\\
  \emptyset\ \ \ & \nonumber \\
  (\mc{p}\  &(g\, (\mc{a}\, \mc{L})) \nonumber \\
                                                   &(f\, g\, (\mc{d}\, \mc{L})))) \nonumber
\end{align}
Aún más, se puede generalizar la estructura del resultado al abstraer el término final $ \emptyset $ y el constructor del par $ \mc{p} $ de la siguiente manera.
\begin{align}
  \label{eq:lis-fold}
  \bs{Y}\, (λf\, \mc{p}\, \emptyset\, g\, \mc{L}.\bs{\prec}\, (\emptyset_{?}&\, \mc{L})\\
  \emptyset\ \ \ & \nonumber \\
  (\mc{p}\  &(g\, (\mc{a}\, \mc{L})) \nonumber \\
                                                   &(f\, \mc{p}\, \emptyset\, g\, (\mc{d}\, \mc{L})))) \nonumber
\end{align}
Si $ \mc{F} $ es la abstracción \eqref{eq:lis-fold}, $ \mc{M} $ es la abstracción \eqref{eq:lis-map}, $ \mc{D} $ es la abstracción \eqref{eq:lis-doubles} y $ \mc{L} $ es el término $ λ $ que codifica la lista $ \langle n_{1},\ ...\ ,\ n_{k} \rangle $, entonces
\[ \mc{F}\, \mc{p}\, \mc{\emptyset}\, (\cn{\times}\, \cn{2})\, \mc{L} \convertible{β} \mc{M}\, (\cn{\times}\, \cn{2})\, \mc{L} \convertible{β} \mc{D}\, \mc{L} \]

Consideremos ahora el \autoref{alg:lis-impares} que dada una lista de números compute una lista únicamente con los números de la lista original que son impares. La estructura de este algoritmo es similar al \autoref{alg:lis-doubles} pero la alternativa de la primer condicional verifica además si el primer elemento $ n $ de $ \mc{L} $ es impar, en cuyo caso $ n $ será elemento de un par resultante; de lo contrario $ n $ es ignorado y no se construye un par en este paso recursivo.

\begin{algorithm}
  \caption{Procedimiento recursivo $ \mathrm{impares}(\mc{L}) $}
  \label{alg:lis-impares}
  \begin{algorithmic}
    \REQUIRE $ \mc{L} \in \{ \langle n_{1},\ ...\ ,\ n_{k} \rangle \mid n\in \mathbb{N} \} \cup \emptyset $
    \ENSURE $ \langle n^{\prime}_{1},\ ...\ ,\ n^{\prime}_{k^{\prime}} \rangle $ ó $ \emptyset \mid n^{\prime}_{i} \in \mc{L},\ n^{\prime}_{i}$ impar
    \IF{$ \mc{L} = \emptyset $}
    \RETURN $ \emptyset $
    \ELSE
    \STATE $ \langle n : \mc{L}^{\prime} \rangle \leftarrow \mc{L} $
    \IF{$ n $ impar}
    \RETURN $ \langle n : \mathrm{impares}(\mc{L}^{\prime}) \rangle $
    \ELSE
    \RETURN $ \mathrm{impares}(\mc{L}^{\prime}) $
    \ENDIF
    \ENDIF
  \end{algorithmic}
\end{algorithm}

La codificación de este algoritmo es bastante directa también, sin embargo, se necesita codificar un predicado que determine si un numeral de Church es impar o no. Un algoritmo recursivo puede ser elegido para la codificación del predicado impar, sin embargo, es más fácil en este caso utilizar la estructura de los numerales para lograr el resultado deseado. Sea $ \cn{imp}_{?} $ la codificación del predicado impar, se deben de satisfacer las siguientes reducciones:
\begin{align*}
  \cn{imp}_{?} (λx\, y.y) &\reduce{β} \bs{F} \\
  \cn{imp}_{?} (λx\, y.x\, y) &\reduce{β} \bs{T} \\
  \cn{imp}_{?} (λx\, y.x\, (x\, y)) &\reduce{β} \bs{F} \\
  \cn{imp}_{?} (λx\, y.x\, (x\, (x\, y))) &\reduce{β} \bs{T} \\
                          &...
\end{align*}
Una manera sencilla de codificar este término es
\[ \cn{imp}_{?} \synteq λn.n\, \bs{\lnot}\, \bs{F} \]
De esta manera
\begin{align*}
  \cn{imp}_{?} (λx\, y.y) &\reduce{β} \bs{F} \\
  \cn{imp}_{?} (λx\, y.x\, y) &\reduce{β} \bs{\lnot}\, \bs{F} \\
  \cn{imp}_{?} (λx\, y.x\, (x\, y)) &\reduce{β} \bs{\lnot}\,  (\bs{\lnot}\, \bs{F}) \\
  \cn{imp}_{?} (λx\, y.x\, (x\, (x\, y))) &\reduce{β} \bs{\lnot}\, (\bs{\lnot}\, (\bs{\lnot}\, \bs{F})) \\
                          &...
\end{align*}
Con este nuevo predicado, la codificación del \autoref{alg:lis-impares} es \eqref{eq:lis-impares}.
\begin{align}
  \label{eq:lis-impares}
  \bs{Y}(λf\, \mc{L}.\bs{\prec} (\emptyset_{?}\, &\mc{L}) \\
                                \emptyset\ \ \ & \nonumber \\
                                (\bs{\prec}\ &(\cn{imp}_{?}\, (\mc{a}\, \mc{L})) \nonumber \\
                                            &(\mc{p}\, (\mc{a}\, \mc{L})\, (f\, (\mc{d}\, \mc{L}))) \nonumber \\
                                            &(f\, (\mc{d}\, \mc{L})))) \nonumber
\end{align}

Esta abstracción también es posible generalizarla con pocas modificaciones para que, además de una lista considere un predicado $ g_{?} $ que sea reducido a una codificación booleana cuando sea aplicado a un numeral de Church. El término \eqref{eq:lis-filter} muestra este término más general.

\begin{align}
  \label{eq:lis-filter}
  \bs{Y}(λf\, g_{?}\, \mc{L}.\bs{\prec}\, (\emptyset_{?}\, &\mc{L}) \\
                                \emptyset\ \ \ & \nonumber \\
                                (\bs{\prec}\ &(g_{?}\, (\mc{a}\, \mc{L})) \nonumber \\
                                            &(\mc{p}\, (\mc{a}\, \mc{L})\, (f\, g_{?}\, (\mc{d}\, \mc{L}))) \nonumber \\
                                            &(f\, g_{?}\, (\mc{d}\, \mc{L})))) \nonumber
\end{align}

Si $ \mc{F} $ es la abstracción \eqref{eq:lis-filter}, $ \mc{I} $ es la abstracción \eqref{eq:lis-impares} y $ \mc{L} $ es el término $ λ $ que codifica la lista $ \langle n_{1},\ ...\ ,\ n_{k} \rangle $, entonces

\[ \mc{F}\, \cn{imp}_{?}\, \mc{L} \convertible{β} \mc{I}\, \mc{L} \]

Algoritmos de procesamiento de listas más complejos pueden ser codificados ya sea utilizando \eqref{eq:lis-map}, \eqref{eq:lis-fold}, \eqref{eq:lis-filter} o términos con una estructura similar. Algo que es importante notar de las generalizaciones planteadas en los ejemplos es que la lista $ \mc{L} $ puede tener términos $ λ $ que no sean numerales, al utilizar los algoritmos genéricos sólo se debe tener cuidado con que la forma de los términos en $ \mc{L} $ sea conocida para $ g $ y $ g_{?} $.

\subsection{Árboles}
\label{sec:estructura-arboles}

Los árboles son estructuras no-lineales jerárquicas compuestos de \emph{vértices} (también llamados \emph{nodos}) y \emph{aristas} que establecen una relación entre dos vértices.

Utilizando pares y listas es posible construír árboles. Consideremos el árbol mostrado en la \autoref{fig:tree}.
\begin{figure}[!htbp]
  \centering
  \begin{tikzpicture}
    \node[circle,draw] (11) {};
    \node (label11) [right= 0cm of 11] {$ v_{1,1} $};
    \node[circle,draw] (21) [below left= .75cm and 1cm of 11] {};
    \node (label21) [left= 0cm of 21] {$ v_{2,1} $};
    \node[circle,draw] (22) [below of=11] {};
    \node (label22) [right= 0cm of 22] {$ v_{2,2} $};
    \node[circle,draw] (23) [below right= .75cm and 1cm of 11] {};
    \node (label23) [right= 0cm of 23] {$ v_{2,3} $};
    \node[circle,draw] (31) [below left=.5cm and .1cm of 21] {};
    \node (label31) [left= 0cm of 31] {$ v_{3,1} $};
    \node[circle,draw] (32) [below right=.5cm and .1cm of 21] {};
    \node (label32) [below= 0cm of 32] {$ v_{3,2} $};
    \node[circle,draw] (33) [below=.43cm of 22] {};
    \node (label33) [right= 0cm of 33] {$ v_{3,3} $};
    \node[circle,draw] (41) [below=.43cm of 31] {};
    \node (label11) [left= 0cm of 41] {$ v_{4,1} $};
    
    \path[draw,thick]
    (11) edge node {} (21)
    (11) edge node {} (22)
    (11) edge node {} (23);

    \path[draw,thick]
    (21) edge node {} (31)
    (21) edge node {} (32);
    
    \path[draw,thick]
    (22) edge node {} (33);

    \path[draw,thick]
    (31) edge node {} (41);
  \end{tikzpicture}
  \caption{Ejemplo de árbol}
  \label{fig:tree}
\end{figure}

La definición usual de un árbol como el mostrado en la figura es como un conjunto de vértices y un conjunto de aristas. Sin embargo, una definición recursiva puede ser expresada como. Un árbol $ \mc{T} $ puede ser o un vértice $ v $ acompañado de una lista de árboles $ \mc{L}_{\mc{T}} $ o un valor nulo $ \emptyset $, es decir

\[ \mc{T} \longrightarrow (v,\ \langle \mc{T}_{1},\ ...\ ,\ \mc{T}_{k} \rangle) \mid \emptyset \]

Esta definición nos permite codificar árboles como el valor nulo o como un par cuyo primer elemento sea un vértice $ v $ y cuyo segundo elemento sea una lista de los vértices en los que $ v $ incide. El vértice puede ser representado por cualquier término $ λ $, en ocaciones es útil asociar un término a cada vértice del árbol para construír, por ejemplo, árboles de numerales.

El árbol de la \autoref{fig:tree} se representa de la siguiente manera:
\begin{align*}
  \langle v_{1,1} : \langle \langle v_{2,1} : \langle &\langle v_{3,1} : \langle \langle v_{4,1} : \emptyset \rangle \rangle \rangle \\
                                                      &\langle v_{3,2} : \emptyset \rangle \rangle \rangle\\
                           \langle v_{2,2} : \langle &\langle v_{3,3} : \emptyset \rangle \rangle \rangle \\
                           \langle v_{2,3} : \emptyset& \rangle \rangle \rangle
\end{align*}

La agrupación entre un vértice y sus subárboles se puede realizar con la estructura par, de tal manera que

\[ \mc{T} \synteq \langle v : \langle \mc{T}_{1},\ ...\ ,\ \mc{T}_{k} \rangle \rangle \convertible{β} \langle v,\ \mc{T}_{1},\ ...\ ,\ \mc{T}_{k} \rangle \]

Por lo que el predicado $ \emptyset_{?} $ funciona para diferenciar árboles nulos de árboles con vértices y si $ \mc{T} $ es un árbol no nulo, entonces $ (\mc{a}\, \mc{T}) $ se reduce al vértice del árbol y $ (\mc{d}\, \mc{T}) $ se reduce a los subárboles del árbol.

Esta similitud en la representación de árboles y listas corresponde con la codificación de listas como ``pares de pares'' y la codificación de árboles como ``listas de listas''. Para mostrar las posibilidades que estas relaciones nos permiten se considera el \autoref{alg:tree-count}, el cual calcula la cantidad de vértices en un árbol. El procedimiento $ \mathrm{suma} $ calcula la suma de los elementos de una lista de numeros y el procedimiento $ \mathrm{map} $ es el que es codificado por \eqref{eq:lis-map}.

\begin{algorithm}
  \caption{Procedimiento recursivo $ \mathrm{cuenta}(\mc{T}) $}
  \label{alg:tree-count}
  \begin{algorithmic}
    \REQUIRE $ \mc{T} \in \{ \langle v : \langle \mc{T}_{1},\ ...\ ,\ \mc{T}_{k} \rangle \rangle \} \cup \emptyset $
    \ENSURE $ n = $ cantidad de vértices en $ \mc{T} $
    \IF{$ \mc{T} = \emptyset $}
    \RETURN $ 0 $
    \ELSE
    \STATE $ \langle v : \mc{L}_{\mc{T}} \rangle \leftarrow \mc{T} $
    \RETURN $ 1 + \mathrm{fold}(+,\ 0,\ \mathrm{cuenta},\ \mc{L}_{\mc{T}}) $
    \ENDIF
  \end{algorithmic}
\end{algorithm}

La codificación del procedimiento $ \mathrm{fold} $ es el término \eqref{eq:lis-fold}. Por lo que el \autoref{alg:tree-count} se define en el cálculo $ λ $ como
\begin{align*}
  \bs{Y}\, (λf\, \mc{T}.\bs{\prec}\, &(\emptyset_{?}\, \mc{T})\\
                                &\cn{0}\\
                                &(\cn{+}_{1}\, (\mc{F}\, \cn{+}\, f\, (\mc{d}\, \mc{T}))))
\end{align*}

\subsection{Gráficas}
\label{sec:estructura-graficas}

Las gráficas son una generalización de árboles en donde se admiten \emph{ciclos}, es decir, a partir de un vértice, se pudieran encontrar dos caminos de aristas para llegar a otro vértice. Consideremos la gráfica mostrada en la \autoref{fig:graph}.

\begin{figure}[!htbp]
  \centering
  \begin{tikzpicture}
    \node[circle,draw] (1) {};
    \node (label1) [above=0cm of 1] {$ v_{1} $};
    \node[circle,draw] (2) [below left of=1] {};
    \node (label2) [left=0cm of 2] {$ v_{2} $};
    \node[circle,draw] (3) [below right of=1] {};
    \node (label3) [below=0cm of 3] {$ v_{3} $};
    \node[circle,draw] (4) [right of=3] {};
    \node (label4) [right=0cm of 4] {$ v_{4} $};

    \path[draw,thick]
    (1) edge node {} (2)
    (1) edge node {} (3)
    (2) edge node {} (3)
    (3) edge node {} (4);
  \end{tikzpicture}
  \caption{Ejemplo de gráfica}
  \label{fig:graph}
\end{figure}

Una posible codificación para las gráficas es como \emph{lista de adyacencia}: Una gráfica $ \mc{G} $ es representada como una lista con un elemento por vértice; cada elemento de esta lista es un par $ \langle v : \mc{L}_{v} \rangle $ donde $ v $ es un término que representa al vértice y $ \mc{L}_{v} $ es una lista con un elemento por vértice en el que $ v $ incida; cada elemento de $ \mc{L}_{v} $ es un término que representa a un vértice.

La gráfica de la \autoref{fig:graph} se representa como lista de adyacencia de la siguiente manera:
\begin{align*}
  \langle &\langle v_{1} : \langle v_{2},\ v_{3} \rangle \rangle\\
          &\langle v_{2} : \langle v_{1},\ v_{3} \rangle \rangle\\
          &\langle v_{3} : \langle v_{1},\ v_{2},\ v_{4} \rangle \rangle\\
          &\langle v_{4} : \langle v_{3} \rangle \rangle \rangle
\end{align*}

La única restricción que se debe incorporar a la codificación es que los vértices puedan ser distinguidos entre sí, esto se puede lograr por ejemplo, utilizando numerales de Church para representar vértices.

Ya que las gráficas son codificadas utilizando términos $ λ $ conocidos, los algoritmos que manipular gráficas pueden ser codificados de manera similar a los presentados en la \autoref{sec:estructura-listas} y \ref{sec:estructura-arboles}.

\subsection{Términos \texorpdfstring{$ \bs{λ} $}{lambda}}
\label{sec:estructura-lambda}

En esta sección se aborda el mecanismo mediante el cual es posible codificar términos $ λ $ dentro del cálculo $ λ $ y de esta manera, tener las herramientas para codificar algoritmos que manipulen términos $ λ $ como la sustitución, la $ α $-contracción, la $ β $-contracción, encontrar los subtérminos de un término, etc.

El hecho de poder codificar términos $ λ $ en el cálculo $ λ $ no introduce problema algúno. Este técnica de representar un lenguaje en sí mismo es común, por ejemplo, en compiladores de \texttt{C} escritos en \texttt{C} o en intérpretes de \texttt{Lisp} escritos en \texttt{Lisp}.

Partiendo de la \autoref{defn:terminos} de término $ λ $, se modifica el conjunto $ V $ para que en lugar de ser $ \{v_{0},\ v_{00},\ v_{000},\ ... \} $, sea $ \{ 0,\ 1,\ 2,\ ... \} $, es decir, que los átomos sean numeros naturales; además en lugar de construír las abstracciones y aplicaciones a partir de símbolos, se construyen a partir de pares.
\begin{defn}[Términos $ λ $]
  El conjunto $ Λ^{\prime} $ tiene elementos que son pares y números naturales. $ Λ^{\prime} $ es el conjunto más pequeño que satisface:
  \label{defn:cod-terminos}
  \begin{subequations}
    \begin{align}
      \label{cod-terminos:atomos} \tag{a}
      n \in \mathbb{N} & \implies n \in Λ^{\prime} \\
      \label{cod-terminos:abstracciones} \tag{b}
      M \in Λ^{\prime},\ n \in \mathbb{N} & \implies  \langle n : M \rangle \in Λ^{\prime} \\
      \label{cod-terminos:aplicaciones} \tag{c}
      M,\ N \in Λ^{\prime} & \implies \langle M : N \rangle \in Λ^{\prime}
    \end{align}
  \end{subequations}
\end{defn}

El problema con esta definición de términos $ λ $ es que no es posible distinguir al término $ (λx.x) $ de $ (x\, x) $. Además, la mayoría de los algoritmos que manipulan términos $ λ $ es crucial poder diferenciar cuando un término $ M $ es un átomo, una abstracción o una aplicación. Para arreglar la \autoref{defn:cod-terminos} se pueden utilizar números que etiqueten cada tipo de término, asignando el número 1 a los átomos, el 2 a las abstracciones y el 3 a las aplicaciones, se tiene una correspondencia uno a uno entre $ Λ $ y $ Λ^{\prime} $.

\begin{defn}[Términos $ λ $]
  El conjunto $ Λ^{\prime} $ tiene elementos que son pares. $ Λ^{\prime} $ es el conjunto más pequeño que satisface:
  \label{defn:cod-terminos2}
  \begin{subequations}
    \begin{align}
      \label{cod-terminos:atomos2} \tag{a}
      n \in \mathbb{N} & \implies \langle 1 : n \rangle \in Λ^{\prime} \\
      \label{cod-terminos:abstracciones2} \tag{b}
      M \in Λ^{\prime},\ n \in \mathbb{N} & \implies \langle 2 : \langle n : M \rangle \rangle \in Λ^{\prime} \\
      \label{cod-terminos:aplicaciones2} \tag{c}
      M,\ N \in Λ^{\prime} & \implies \langle 3 : \langle M : N \rangle \rangle \in Λ^{\prime}
    \end{align}
  \end{subequations}
\end{defn}

Con esta definición, el término $ (λx.x) $ se puede representar como $ \langle 2 : \langle \langle 1 : n \rangle : \langle 1 : n \rangle \rangle \rangle $ y el término $ (x\, x) $ se puede representar como $ \langle 3 : \langle \langle 1 : n \rangle : \langle 1 : n \rangle \rangle \rangle $.

Codificaciones adecuadas para los constructores y selectores de esta representación de términos $ λ $ se basan en las técnicas abordadas a lo largo de este capítulo.

Sea $ \mc{T} $ la codificación de un término $ λ $, los predicados $ \mathrm{atomo}_{?} $, $ \mathrm{abstraccion}_{?} $ y $ \mathrm{aplicacion}_{?} $ permiten determinar la clase de término que es $ \mc{T} $:
\begin{align}
  \label{eq:cod-lambda-preds}
  \mathrm{atomo}_{?} &\synteq λ\mc{T}.\cn{=}_{?}\, \cn{1} (\mc{a}\, \mc{T})\\
  \mathrm{abstraccion}_{?} &\synteq λ\mc{T}.\cn{=}_{?}\, \cn{2} (\mc{a}\, \mc{T})\\
  \mathrm{aplicacion}_{?} &\synteq λ\mc{T}.\cn{=}_{?}\, \cn{3} (\mc{a}\, \mc{T})
\end{align}

Utilizando estos tres predicados y el término $ \bs{\prec} $ se puede codificar un término que funcione como una estructura de control similar a $ \bs{\prec} $ que a partir de un término codificado $ \mc{T} $ y cuatro términos $ M_{1} $, $ M_{2} $, $ M_{3} $ y $ M_{4} $ compute $ M_{1} $ si $ \mc{T} $ es un átomo, $ M_{2} $ si es una abstracción, $ M_{3} $ si es una aplicación y $ M_{4} $ en otro caso:
\begin{equation}
  \label{eq:cod-lambda-match}
  \mathrm{ramifica} \synteq λ\mc{T}\, x\, y\, z\, e.\bs{\prec} (\mathrm{atomo}_{?}\, \mc{T}) x (\bs{\prec} (\mathrm{abstraccion}_{?}\, \mc{T}) y (\bs{\prec} (\mathrm{aplicacion}_{?}\, \mc{T}) z\, e))
\end{equation}

Los constructores para cada clase de término $ λ $ siguen la \autoref{defn:cod-terminos2}:
\begin{align}
  \label{eq:cod-lambda-cons}
  \mathrm{atomo} &\synteq λn.\mc{p}\, \cn{1}\, n \\
  \mathrm{abstraccion} &\synteq λn\, x.\mc{p}\, \cn{2} (\mc{p}\, n\, x) \\
  \mathrm{aplicacion} &\synteq λx\, y.\mc{p}\, \cn{3} (\mc{p}\, x\, y)
\end{align}

Los constructores en \eqref{eq:cod-lambda-cons} deben satisfacer los predicados en \eqref{eq:cod-lambda-preds}, se corrobora esto con los siguientes desarrollos.
\begin{align*}
  \mathrm{atomo}_{?}\, (\mathrm{atomo}\, \cn{n}) &\synteq (λ\mc{T}.\cn{=}_{?}\, \cn{1}\, (\mc{a}\, \mc{T}))\, (\mathrm{atomo}\, \cn{n}) \\
                                               &\contract{β} \cn{=}_{?}\, \cn{1}\, (\mc{a} (\mathrm{atomo}\, \cn{n})) \\
                                               &\synteq \cn{=}_{?}\, \cn{1}\, (\mc{a}\, ((λn.\mc{p}\, \cn{1}\, n)\, \cn{n})) \\
                                               &\contract{β} \cn{=}_{?}\, \cn{1}\, (\mc{a}\, (\mc{p}\, \cn{1}\, \cn{n})) \\
                                               &\reduce{β} \cn{=}_{?}\, \cn{1}\, \cn{1} \reduce{β} \bs{T}
\end{align*}
\begin{align*}
  \mathrm{atomo}_{?}\, (\mathrm{aplicacion}\, M\, N) &\synteq (λ\mc{T}.\cn{=}_{?}\, \cn{1}\, (\mc{a}\, \mc{T}))\, (\mathrm{aplicacion}\, M\, N) \\
                                               &\contract{β} \cn{=}_{?}\, \cn{1}\, (\mc{a}\, (\mathrm{aplicacion}\, M\, N)) \\
                                               &\synteq \cn{=}_{?}\, \cn{1}\, (\mc{a}\, ((λx\, y.\mc{p}\, \cn{3}\, (\mc{p}\, x\, y))\, M\, N)) \\
                                               &\reduce{β} \cn{=}_{?}\, \cn{1}\, (\mc{a}\, (\mc{p}\, \cn{3}\, (\mc{p}\, M\, N))) \\
                                               &\reduce{β} \cn{=}_{?}\, \cn{1}\, \cn{3} \reduce{β} \bs{F}
\end{align*}
Corroborar que las otras combinaciones de aplicaciones se reducen de manera correcta implica un desarrollo similar.

Los selectores para cada clase de término $ λ $ se codifican en función de la cantidad de elementos que conforman al término. Los átomos tienen un selector, las abstracciones dos y las aplicaciones dos. Debido a que las abstracciones comparten la misma estructura, sus selectores son los mismos.

\begin{align}
  \label{eq:cod-lambda-selec}
  \mathrm{atomo}_{n} &\synteq λx.\mc{d}\, x \\
  \mathrm{abstraccion}_{v} &\synteq λx.\mc{a} (\mc{d}\, x) \\
  \mathrm{abstraccion}_{t} &\synteq λx.\mc{d} (\mc{d}\, x) \\
  \mathrm{aplicacion}_{o} &\synteq λx.\mc{a} (\mc{d}\, x) \\
  \mathrm{aplicacion}_{a} &\synteq λx.\mc{d} (\mc{d}\, x)
\end{align}

La técnica de etiquetar pares para poder determinar el ``tipo'' de estructura es muy utilizada en la implementación de lenguajes de programación con verificación dinámica de tipos. La flexibilidad de la técnica permite codificar todos los objetos que se han abordado en este trabajo como pares etiquetados, los valores de verdad pueden etiquetarse con el 4, los numerales de Church con el 5, los pares con el 6 y así sucesivamente. De esta manera la codificación de algoritmos en el cálculo $ λ $  puede ser más robusta, evitando errores que puedan surgir al reducir los términos.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
